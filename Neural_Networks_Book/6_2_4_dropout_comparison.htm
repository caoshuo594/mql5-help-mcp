<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <title>6.2.4 Comparative testing of models with Dropout</title>
  <meta name="keywords" content="" />
  <link type="text/css" href="default.css" rel="stylesheet" />

   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>


</head>

<body style="background-color:#FFFFFF; font-family:'Trebuchet MS',Tahoma,Arial,Helvetica,sans-serif; margin:0px;">



<table width="100%" height="49"  border="0" cellpadding="0" cellspacing="0" style="margin-top:0px; background-color:#1660af;">
  <tr>
    <td></td>
    <td valign="middle">
      <table style="margin-top:4px; margin-bottom:5px;" width="100%"  border="0" cellspacing="0" cellpadding="5">
        <tr valign="middle">
          <td class="nav">
<a class="h_m" href="index.htm">          Neural Networks for Algorithmic Trading with MQL5 </a> / <a class="h_m" href="6_improvement_realization.htm"> 6. Architectural solutions for improving model convergence </a> / <a class="h_m" href="6_2_dropout_realization.htm"> 6.2 Dropout </a>/ 6.2.4 Comparative testing of models with Dropout
          </td>
          <td width="70" align="right">
          <a href="6_2_3_dropout_py.htm"><img style="vertical-align:middle;" src="previous.png" alt="?????" width="27" height="27" border=0></a>&nbsp;
          <a href="7_trade_check.htm"><img style="vertical-align:middle;" src="next.png" alt="??????" width="27" height="27" border="0"></a>
          </td>
        </tr>
      </table>
    </td>
    <td width="5"></td>
  </tr>
</table>



<div id="help">
<p class="p_H3"><span class="f_H3">6.2.4 Comparative testing of models with Dropout</span></p>
<p class="p_Text"><span class="f_Text">Another stage of work with our library has been completed. We have studied the </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> method, which combats the issue of feature co-adaptation and have built a class to implement this algorithm in our models. In the previous section, we assembled a </span><span class="f_Text" style="font-style: italic;">Python</span><span class="f_Text"> script for the comparative testing of models using this method and without. Let's look at the results of such testing.</span></p>
<p class="p_Text"><span class="f_Text">First, we look at the test training schedule for models with one hidden layer. The dynamics of the mean square error of the models using </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> was worse than that of models without it. This applies to both the model trained on normalized data and the model using batch normalization layers for preprocessing the input data. You can see that both models using the </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> layer worked synchronously. Their lines on the graph are practically overlapping, both during the training and validation phases.</span></p>
<p class="p_Text"><span class="f_Text">Similar conclusions can be drawn when analyzing the dynamics of </span><span class="f_Text" style="font-style: italic;">Accuracy</span><span class="f_Text"> metrics. However, unlike the </span><span class="f_Text" style="font-style: italic;">MSE</span><span class="f_Text">, accuracy values in the validation process are close to those of other models.</span></p>
<p class="p_Text"><span class="f_Text">The evaluation of models on the test dataset also showed deterioration in model performance when using the </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> layer, both for mean square error and for </span><span class="f_Text" style="font-style: italic;">Accuracy.</span><span class="f_Text"> The reasons for such a phenomenon can only be speculated upon. One of the possible reasons can be attributed to the use of models that are too simple. The models didn't have too many neurons, and masking some of them reduces the capabilities of the model, which are already limited by the small number of neurons being used.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout" title="Comparative model testing with Dropout" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_train_mse_1l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout</span></p></div></div>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout" title="Comparative model testing with Dropout" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_train_acc_1l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout</span></p></div></div>
<p class="p_Text"><span class="f_Text">On the other hand, we chose uncorrelated variables at the data selection stage. Probably due to the small number of features being used and the absence of strong correlations between them, co-adaptation might not be highly developed in our models. As a result, the negative impact of using </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> in terms of degrading the model performance may have outweighed the positive effects of the method.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout (test sample)" title="Comparative model testing with Dropout (test sample)" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_mse_1l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout (test sample)</span></p></div></div>
<p class="p_Text" style="text-align: center;"><span class="f_Text">&nbsp;</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout (test sample)" title="Comparative model testing with Dropout (test sample)" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_accuracy_1l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout (test sample)</span></p></div></div>
<p class="p_Text"><span class="f_Text">That is just my guess. I do not have enough information to draw certain conclusions. Additional tests will be required. However, it is more the focus of scientific work, while our goal is the practical use of models. We conduct experiments with various architectural solutions and choose the best one for each specific task.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout" title="Comparative model testing with Dropout" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_train_mse_3l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout</span></p></div></div>
<p class="p_Text"><span class="f_Text">The second test was performed using a </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> layer before each fully connected layer in models with three hidden layers. Again, models with the </span><span class="f_Text" style="font-style: italic;">Dropout </span><span class="f_Text">layer performed worse than other models in the learning process. However, during the validation process, the situation tends to change somewhat. While models without the use of </span><span class="f_Text" style="font-style: italic;">Dropout </span><span class="f_Text">layers tend to decrease their performance on the validation stage with an increase in the number of training epochs, models using this technology slightly improve their positions or remain at a similar level.</span></p>
<p class="p_Text"><span class="f_Text">This suggests that the use of a </span><span class="f_Text" style="font-style: italic;">Dropout </span><span class="f_Text">layer reduces the likelihood of model overfitting.</span></p>
<p class="p_Text"><span class="f_Text">The graph showing the dynamics of </span><span class="f_Text" style="font-style: italic;">Accuracy</span><span class="f_Text"> values during training confirms the conclusion made earlier. With the increasing number of model training epochs, without the use of the </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> layer, there is a widening gap between the values in the training and validation phases. This indicates a retraining of the model. For models using </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> technology, the gap is narrowing. This supports the earlier conclusion that the use of a</span><span class="f_Text" style="font-style: italic;"> Dropout</span><span class="f_Text"> layer reduces the tendency of the model to overfit.</span></p>
<p class="p_Text"><span class="f_Text">On the test dataset, models using the </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> layer showed worse results in both metrics.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout" title="Comparative model testing with Dropout" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_train_acc_3l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout</span></p></div></div>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout (test sample)" title="Comparative model testing with Dropout (test sample)" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_mse_3l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout (test sample)</span></p></div></div>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" alt="Comparative model testing with Dropout (test sample)" title="Comparative model testing with Dropout (test sample)" width="600" height="400" style="width:600px;height:400px;border:none" src="dropout_accuracy_3l.png"/><p style="text-align:center"><span class="f_ImageCaption">Comparative model testing with Dropout (test sample)</span></p></div></div>
<p class="p_Text"><span class="f_Text">In this section, we have run comparative model testing with </span><span class="f_Text" style="font-style: italic;">Dropout</span><span class="f_Text"> technology and without it. The following conclusions can be drawn from the tests:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li">The use of the Dropout technology helps reduce the risk of model overfitting.</span></li>
<li class="p_li"><span class="f_li">The effectiveness of the Dropout technology increases as the model size grows.</span></li>
</ul>

</div>

</body>
</html>
