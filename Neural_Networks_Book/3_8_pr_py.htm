<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <title>3.8 Implementing the perceptron model in Python</title>
  <meta name="keywords" content="" />
  <link type="text/css" href="default.css" rel="stylesheet" />

   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>


</head>

<body style="background-color:#FFFFFF; font-family:'Trebuchet MS',Tahoma,Arial,Helvetica,sans-serif; margin:0px;">



<table width="100%" height="49"  border="0" cellpadding="0" cellspacing="0" style="margin-top:0px; background-color:#1660af;">
  <tr>
    <td></td>
    <td valign="middle">
      <table style="margin-top:4px; margin-bottom:5px;" width="100%"  border="0" cellspacing="0" cellpadding="5">
        <tr valign="middle">
          <td class="nav">
<a class="h_m" href="index.htm">          Neural Networks for Algorithmic Trading with MQL5 </a> / <a class="h_m" href="3_realization.htm"> 3. Building the first neural network model in MQL5 </a>/ 3.8 Implementing the perceptron model in Python
          </td>
          <td width="70" align="right">
          <a href="3_7_2_opencl_transfer_data.htm"><img style="vertical-align:middle;" src="previous.png" alt="?????" width="27" height="27" border=0></a>&nbsp;
          <a href="3_9_create_data.htm"><img style="vertical-align:middle;" src="next.png" alt="??????" width="27" height="27" border="0"></a>
          </td>
        </tr>
      </table>
    </td>
    <td width="5"></td>
  </tr>
</table>



<div id="help">
<p class="p_H2"><span class="f_H2">3.8 Implementing the perceptron model in Python</span></p>
<p class="p_Text"><span class="f_Text">To implement the fully connected perceptron model in Python, we will use the <a href="3_5_py_struct.htm" class="topiclink">template</a> we created earlier. As you may recall, in this template, we left the description of the neural layers in our model unfilled.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Create&nbsp;a&nbsp;neural&nbsp;network&nbsp;model</span>
<br><span class="f_CodeExample">model&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Fill&nbsp;the&nbsp;model&nbsp;with&nbsp;a&nbsp;description&nbsp;of&nbsp;the&nbsp;neural&nbsp;layers</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">To create fully connected layers in a neural network, we will use the </span><span class="f_Text" style="font-style: italic;">layers.Dense</span><span class="f_Text"> class from the </span><span class="f_Text" style="font-style: italic;">Keras</span><span class="f_Text"> library. The following operation is performed within this layer:</span></p>
<p class="p_Text" style="text-align: center;"><span style="display:inline-block;width:404px;height:17px;padding:0 0;overflow:visible"><svg xmlns="http://www.w3.org/2000/svg" style="width:100%;height:100%;overflow:visible" viewBox="0 0 1616 68"><path d="M31 2 C36 2,39 4,42 6 C45 9,46 13,46 18 C46 22,45 27,44 31 C43 36,41 40,38 44 C36 47,33 50,30 52 C27 53,23 54,20 54 C15 54,11 53,9 50 C6 47,5 43,5 38 C5 34,6 30,7 25 C8 21,10 17,12 13 C15 9,17 7,21 5 C24 3,27 2,31 2 L31 2 Z M39 17 C39 9,36 5,31 5 C28 5,26 6,23 8 C21 10,19 13,17 16 C16 20,14 24,13 28 C12 32,12 36,12 39 C12 47,15 51,20 51 C23 51,27 50,29 46 C32 43,34 39,36 33 C38 27,39 22,39 17 L39 17 Z" fill="#212121"/><path d="M84 42 C84 44,83 46,83 47 C83 48,83 49,84 49 C84 50,85 50,85 50 C86 50,87 50,88 49 C88 49,90 48,91 46 L93 48 C91 50,89 52,88 53 C86 54,84 54,83 54 C81 54,80 54,79 53 C78 52,78 50,78 49 C78 48,78 46,78 45 L78 44 C76 48,73 50,71 52 C69 53,67 54,64 54 C62 54,60 53,59 52 C58 51,57 49,57 46 C57 45,58 43,58 40 L61 30 C61 27,62 25,62 24 C62 23,62 22,61 22 C61 21,61 21,60 21 C59 21,58 21,57 22 C57 23,55 24,54 25 L52 23 C54 21,56 20,57 19 C58 18,59 18,60 18 C61 17,62 17,63 17 C64 17,66 18,67 19 C67 20,68 21,68 23 C68 25,68 28,67 31 L65 37 C65 39,64 40,64 41 C64 42,64 43,64 43 C64 44,64 45,64 45 C64 47,64 48,65 49 C65 50,66 50,67 50 C68 50,69 50,71 49 C72 48,73 47,74 45 C76 43,77 42,78 40 C78 39,79 37,80 34 L83 18 L89 18 L84 42 Z" fill="#212121"/><path d="M119 46 C117 49,115 51,113 52 C111 53,109 54,107 54 C102 54,100 52,100 46 C100 45,100 43,100 41 L104 22 L98 22 L99 20 C100 20,101 20,102 20 C103 20,103 19,104 19 C104 19,105 18,105 17 C106 17,106 16,107 15 C107 14,108 12,108 9 L113 9 L111 18 L122 18 L122 22 L111 22 L107 36 C107 39,106 41,106 43 C106 44,106 45,106 45 C106 49,107 50,110 50 C111 50,112 50,113 49 C114 48,116 46,117 44 L119 46 Z" fill="#212121"/><path d="M134 30 C135 27,135 25,135 24 C135 23,135 22,134 22 C134 21,134 21,133 21 C132 21,131 21,130 22 C130 23,128 24,127 25 L125 23 C127 21,129 19,130 18 C132 18,134 17,136 17 C137 17,138 18,139 19 C140 20,140 21,140 22 C140 24,140 25,140 27 L140 27 C145 20,149 17,154 17 C156 17,158 18,160 20 C161 22,162 25,162 29 C162 33,161 37,160 41 C158 45,156 48,153 51 C150 53,147 54,143 54 C140 54,137 53,135 52 L133 60 C133 62,133 63,133 64 C133 65,133 66,134 66 C134 67,135 67,137 67 L137 69 L125 69 L134 30 Z M138 40 C137 42,137 43,137 43 C137 44,137 45,137 45 C137 47,138 49,138 50 C139 51,141 51,143 51 C144 51,145 51,146 50 C147 50,148 49,149 48 C150 47,151 46,152 45 C152 43,153 42,154 40 C154 38,155 36,155 34 C155 32,155 31,155 29 C155 26,155 24,154 23 C154 22,153 21,151 21 C150 21,149 22,147 22 C146 23,145 25,143 27 C142 29,141 30,140 32 C139 34,139 36,138 39 L138 40 Z" fill="#212121"/><path d="M199 42 C199 44,198 46,198 47 C198 48,198 49,199 49 C199 50,200 50,200 50 C201 50,202 50,203 49 C203 49,205 48,206 46 L208 48 C206 50,204 52,203 53 C201 54,199 54,198 54 C196 54,195 54,194 53 C193 52,193 50,193 49 C193 48,193 46,193 45 L193 44 C191 48,188 50,186 52 C184 53,182 54,179 54 C177 54,175 53,174 52 C173 51,172 49,172 46 C172 45,173 43,173 40 L176 30 C176 27,177 25,177 24 C177 23,177 22,176 22 C176 21,176 21,175 21 C174 21,173 21,172 22 C172 23,170 24,169 25 L167 23 C169 21,171 20,172 19 C173 18,174 18,175 18 C176 17,177 17,178 17 C179 17,181 18,182 19 C182 20,183 21,183 23 C183 25,183 28,182 31 L180 37 C180 39,179 40,179 41 C179 42,179 43,179 43 C179 44,179 45,179 45 C179 47,179 48,180 49 C180 50,181 50,182 50 C183 50,184 50,186 49 C187 48,188 47,189 45 C191 43,192 42,193 40 C193 39,194 37,195 34 L198 18 L204 18 L199 42 Z" fill="#212121"/><path d="M234 46 C232 49,230 51,228 52 C226 53,224 54,222 54 C217 54,215 52,215 46 C215 45,215 43,215 41 L219 22 L213 22 L214 20 C215 20,216 20,217 20 C218 20,218 19,219 19 C219 19,220 18,220 17 C221 17,221 16,222 15 C222 14,223 12,223 9 L228 9 L226 18 L237 18 L237 22 L226 22 L222 36 C222 39,221 41,221 43 C221 44,221 45,221 45 C221 49,222 50,225 50 C226 50,227 50,228 49 C229 48,231 46,232 44 L234 46 Z" fill="#212121"/><path d="M267 27 L267 22 L313 22 L313 27 L267 27 Z M267 42 L267 37 L313 37 L313 42 L267 42 Z" fill="#212121"/><path d="M370 20 L374 17 L376 18 L371 42 C370 44,370 46,370 47 C370 48,370 49,370 49 C371 50,371 50,372 50 C373 50,374 50,374 49 C375 49,376 48,378 46 L380 48 C378 50,376 52,374 53 C373 54,371 54,369 54 C368 54,367 54,366 53 C365 52,364 50,364 49 C364 48,365 46,365 45 L365 44 C362 48,360 50,358 52 C356 53,354 54,351 54 C349 54,347 53,345 51 C344 49,343 46,343 42 C343 38,344 34,345 30 C347 26,349 23,352 21 C355 18,358 17,362 17 C363 17,365 17,366 18 C368 18,369 19,370 20 L370 20 Z M367 31 C367 30,368 29,368 28 C368 27,368 27,368 26 C368 24,367 22,367 21 C366 21,364 20,362 20 C360 20,358 21,356 23 C354 25,352 28,351 32 C350 35,349 39,349 42 C349 45,350 47,350 48 C351 49,352 50,354 50 C356 50,357 49,359 48 C360 47,362 44,363 42 C365 39,366 36,367 32 L367 31 Z" fill="#212121"/><path d="M409 27 C409 25,408 24,408 23 C408 22,407 21,407 21 C406 20,406 20,404 20 C402 20,400 21,398 23 C396 25,394 28,393 32 C392 36,391 39,391 42 C391 45,392 47,393 48 C394 49,395 50,397 50 C399 50,401 50,403 49 C404 48,406 47,408 45 L410 47 C408 50,406 51,403 52 C401 54,398 54,396 54 C392 54,389 53,388 51 C386 49,385 46,385 41 C385 39,385 36,386 33 C387 30,389 27,391 24 C392 22,395 20,397 19 C400 18,402 17,405 17 C409 17,411 17,414 18 L412 27 L409 27 Z" fill="#212121"/><path d="M441 46 C439 49,437 51,435 52 C433 53,431 54,429 54 C424 54,422 52,422 46 C422 45,422 43,422 41 L426 22 L420 22 L421 20 C422 20,423 20,424 20 C425 20,425 19,426 19 C426 19,427 18,427 17 C428 17,428 16,429 15 C429 14,430 12,430 9 L435 9 L433 18 L444 18 L444 22 L433 22 L429 36 C429 39,428 41,428 43 C428 44,428 45,428 45 C428 49,429 50,432 50 C433 50,434 50,435 49 C436 48,438 46,439 44 L441 46 Z" fill="#212121"/><path d="M467 3 L465 10 L459 10 L460 3 L467 3 Z M455 29 C455 26,456 24,456 23 C456 22,455 21,455 21 C454 20,453 20,452 20 L452 18 L461 17 L463 17 L458 42 C458 44,457 46,457 47 C457 48,457 49,458 49 C458 50,459 50,459 50 C460 50,461 50,462 49 C462 49,464 48,465 46 L467 48 C465 50,463 52,461 53 C460 54,458 54,456 54 C455 54,454 53,453 52 C452 51,451 50,451 48 C451 46,452 44,452 41 L455 29 Z" fill="#212121"/><path d="M483 54 C482 54,482 54,481 54 C481 53,480 53,480 52 C480 51,480 51,479 50 C479 49,479 48,479 47 C479 45,479 44,480 42 C480 40,480 39,480 37 L482 27 C482 26,482 26,482 25 C482 24,482 24,482 24 C482 23,482 22,482 22 C481 21,481 21,480 21 C480 21,480 21,479 22 C478 22,478 22,477 23 C477 23,476 24,476 24 C475 25,475 25,474 25 L473 23 C473 23,474 22,475 21 C476 20,477 20,478 19 C479 19,480 18,481 18 C482 17,483 17,484 17 C485 17,486 17,486 18 C487 18,487 18,488 19 C488 19,488 20,488 20 C488 21,488 22,488 22 C488 23,488 23,488 23 C488 24,488 24,488 24 L486 38 C486 39,486 41,486 42 C486 43,485 45,485 46 C485 47,486 47,486 48 C486 49,486 49,486 49 C487 49,488 49,489 48 C491 47,492 47,493 45 C495 44,496 43,497 41 C499 40,500 38,501 36 C502 34,503 32,504 30 C504 28,505 26,505 24 C505 23,504 22,504 22 C504 21,503 21,502 21 C501 21,500 22,499 22 C498 23,498 24,497 25 L495 24 C495 23,496 22,497 21 C497 20,498 20,499 19 C500 18,501 18,502 18 C503 17,504 17,505 17 C506 17,508 18,509 18 C509 19,510 21,510 22 C510 23,509 25,509 26 C509 28,508 30,507 31 C507 33,506 35,505 36 C504 38,502 40,501 42 C500 43,499 45,497 47 C496 48,494 49,493 50 C491 52,489 52,488 53 C486 54,485 54,483 54 L483 54 Z" fill="#212121"/><path d="M542 20 L546 17 L548 18 L543 42 C542 44,542 46,542 47 C542 48,542 49,542 49 C543 50,543 50,544 50 C545 50,546 50,546 49 C547 49,548 48,550 46 L552 48 C550 50,548 52,546 53 C545 54,543 54,541 54 C540 54,539 54,538 53 C537 52,536 50,536 49 C536 48,537 46,537 45 L537 44 C534 48,532 50,530 52 C528 53,526 54,523 54 C521 54,519 53,517 51 C516 49,515 46,515 42 C515 38,516 34,517 30 C519 26,521 23,524 21 C527 18,530 17,534 17 C535 17,537 17,538 18 C540 18,541 19,542 20 L542 20 Z M539 31 C539 30,540 29,540 28 C540 27,540 27,540 26 C540 24,539 22,539 21 C538 21,536 20,534 20 C532 20,530 21,528 23 C526 25,524 28,523 32 C522 35,521 39,521 42 C521 45,522 47,522 48 C523 49,524 50,526 50 C528 50,529 49,531 48 C532 47,534 44,535 42 C537 39,538 36,539 32 L539 31 Z" fill="#212121"/><path d="M578 46 C576 49,574 51,572 52 C570 53,568 54,566 54 C561 54,559 52,559 46 C559 45,559 43,559 41 L563 22 L557 22 L558 20 C559 20,560 20,561 20 C562 20,562 19,563 19 C563 19,564 18,564 17 C565 17,565 16,566 15 C566 14,567 12,567 9 L572 9 L570 18 L581 18 L581 22 L570 22 L566 36 C566 39,565 41,565 43 C565 44,565 45,565 45 C565 49,566 50,569 50 C570 50,571 50,572 49 C573 48,575 46,576 44 L578 46 Z" fill="#212121"/><path d="M604 3 L602 10 L596 10 L597 3 L604 3 Z M592 29 C592 26,593 24,593 23 C593 22,592 21,592 21 C591 20,590 20,589 20 L589 18 L598 17 L600 17 L595 42 C595 44,594 46,594 47 C594 48,594 49,595 49 C595 50,596 50,596 50 C597 50,598 50,599 49 C599 49,601 48,602 46 L604 48 C602 50,600 52,598 53 C597 54,595 54,593 54 C592 54,591 53,590 52 C589 51,588 50,588 48 C588 46,589 44,589 41 L592 29 Z" fill="#212121"/><path d="M623 54 C619 54,616 53,614 51 C612 49,611 46,611 41 C611 40,611 37,612 35 C613 31,614 28,616 25 C618 23,620 21,622 19 C625 18,628 17,631 17 C635 17,638 18,640 20 C642 23,643 26,643 30 C643 33,642 36,641 39 C640 42,639 45,637 47 C636 50,634 51,631 52 C629 54,626 54,623 54 L623 54 Z M617 43 C617 46,618 48,619 49 C620 50,622 51,624 51 C627 51,629 50,631 48 C632 46,634 43,635 39 C636 35,637 31,637 28 C637 26,636 24,635 22 C634 21,632 20,630 20 C628 20,625 21,624 23 C622 26,620 29,619 33 C618 37,617 40,617 43 L617 43 Z" fill="#212121"/><path d="M657 29 C658 27,658 25,658 24 C658 23,658 22,657 22 C657 21,657 21,656 21 C655 21,654 21,653 22 C653 23,651 24,650 25 L648 23 C650 21,652 19,654 18 C655 18,657 17,659 17 C660 17,661 18,662 19 C663 20,664 21,664 22 C664 24,663 25,663 27 L663 27 C665 23,668 21,670 19 C672 18,674 17,677 17 C679 17,681 18,682 19 C683 20,684 22,684 25 C684 26,683 29,683 31 L680 41 C680 44,679 46,679 47 C679 48,679 49,680 49 C680 50,681 50,681 50 C682 50,683 50,684 49 C684 49,686 48,687 46 L689 48 C687 50,685 52,684 53 C682 54,680 54,678 54 C677 54,676 53,675 52 C674 51,673 50,673 48 C673 46,674 44,674 41 L676 34 C677 32,677 30,677 29 C677 28,677 27,677 26 C677 24,677 23,677 22 C676 21,675 21,674 21 C673 21,672 22,670 22 C669 23,668 24,667 26 C665 28,664 29,663 31 C663 33,662 35,661 37 L658 53 L652 53 L657 29 Z" fill="#212121"/><path d="M704 35 C704 43,705 51,708 56 C711 62,715 65,721 67 L720 70 C713 68,707 64,704 58 C700 52,698 44,698 35 C698 26,700 19,704 12 C707 6,713 2,720 0 L721 3 C715 5,711 9,708 14 C705 20,704 26,704 35 L704 35 Z" fill="#212121"/><path d="M748 44 C745 48,743 50,741 52 C739 53,737 54,734 54 C732 54,730 53,728 51 C727 49,726 46,726 42 C726 38,727 34,728 30 C730 26,732 23,735 21 C738 18,741 17,745 17 C746 17,748 17,749 18 C750 18,751 18,753 19 L755 11 C755 10,755 9,755 8 C755 7,755 7,755 6 C755 5,755 5,755 4 C755 4,754 4,754 3 C753 3,752 3,751 3 L752 1 L761 1 L763 1 L754 42 C753 44,753 46,753 47 C753 48,753 49,753 49 C754 50,754 50,755 50 C756 50,757 50,757 49 C758 49,759 48,761 46 L763 48 C761 50,759 52,757 53 C756 54,754 54,752 54 C751 54,750 54,749 53 C748 52,747 50,747 49 C747 48,748 46,748 45 L748 44 Z M750 31 C750 29,751 27,751 26 C751 24,750 22,749 21 C749 21,747 20,745 20 C743 20,741 21,739 23 C737 25,735 28,734 32 C733 35,732 39,732 42 C732 45,733 47,733 48 C734 49,735 50,737 50 C738 50,738 50,739 50 C740 49,741 49,742 48 C743 47,743 46,744 45 C745 44,746 43,746 42 C747 41,748 40,748 38 C749 36,749 35,750 32 L750 31 Z" fill="#212121"/><path d="M781 54 C777 54,774 53,772 51 C770 49,769 46,769 41 C769 40,769 37,770 35 C771 31,772 28,774 25 C776 23,778 21,780 19 C783 18,786 17,789 17 C793 17,796 18,798 20 C800 23,801 26,801 30 C801 33,800 36,799 39 C798 42,797 45,795 47 C794 50,792 51,789 52 C787 54,784 54,781 54 L781 54 Z M775 43 C775 46,776 48,777 49 C778 50,780 51,782 51 C785 51,787 50,789 48 C790 46,792 43,793 39 C794 35,795 31,795 28 C795 26,794 24,793 22 C792 21,790 20,788 20 C786 20,783 21,782 23 C780 26,778 29,777 33 C776 37,775 40,775 43 L775 43 Z" fill="#212121"/><path d="M830 46 C828 49,826 51,824 52 C822 53,820 54,818 54 C813 54,811 52,811 46 C811 45,811 43,811 41 L815 22 L809 22 L810 20 C811 20,812 20,813 20 C814 20,814 19,815 19 C815 19,816 18,816 17 C817 17,817 16,818 15 C818 14,819 12,819 9 L824 9 L822 18 L833 18 L833 22 L822 22 L818 36 C818 39,817 41,817 43 C817 44,817 45,817 45 C817 49,818 50,821 50 C822 50,823 50,824 49 C825 48,827 46,828 44 L830 46 Z" fill="#212121"/><path d="M850 35 C850 43,851 51,854 56 C857 62,861 65,867 67 L866 70 C859 68,853 64,850 58 C846 52,844 44,844 35 C844 26,846 19,850 12 C853 6,859 2,866 0 L867 3 C861 5,857 9,854 14 C851 20,850 26,850 35 L850 35 Z" fill="#212121"/><path d="M889 3 L887 10 L881 10 L882 3 L889 3 Z M877 29 C877 26,878 24,878 23 C878 22,877 21,877 21 C876 20,875 20,874 20 L874 18 L883 17 L885 17 L880 42 C880 44,879 46,879 47 C879 48,879 49,880 49 C880 50,881 50,881 50 C882 50,883 50,884 49 C884 49,886 48,887 46 L889 48 C887 50,885 52,883 53 C882 54,880 54,878 54 C877 54,876 53,875 52 C874 51,873 50,873 48 C873 46,874 44,874 41 L877 29 Z" fill="#212121"/><path d="M902 29 C903 27,903 25,903 24 C903 23,903 22,902 22 C902 21,902 21,901 21 C900 21,899 21,898 22 C898 23,896 24,895 25 L893 23 C895 21,897 19,899 18 C900 18,902 17,904 17 C905 17,906 18,907 19 C908 20,909 21,909 22 C909 24,908 25,908 27 L908 27 C910 23,913 21,915 19 C917 18,919 17,922 17 C924 17,926 18,927 19 C928 20,929 22,929 25 C929 26,928 29,928 31 L925 41 C925 44,924 46,924 47 C924 48,924 49,925 49 C925 50,926 50,926 50 C927 50,928 50,929 49 C929 49,931 48,932 46 L934 48 C932 50,930 52,929 53 C927 54,925 54,923 54 C922 54,921 53,920 52 C919 51,918 50,918 48 C918 46,919 44,919 41 L921 34 C922 32,922 30,922 29 C922 28,922 27,922 26 C922 24,922 23,922 22 C921 21,920 21,919 21 C918 21,917 22,915 22 C914 23,913 24,912 26 C910 28,909 29,908 31 C908 33,907 35,906 37 L903 53 L897 53 L902 29 Z" fill="#212121"/><path d="M945 30 C946 27,946 25,946 24 C946 23,946 22,945 22 C945 21,945 21,944 21 C943 21,942 21,941 22 C941 23,939 24,938 25 L936 23 C938 21,940 19,941 18 C943 18,945 17,947 17 C948 17,949 18,950 19 C951 20,951 21,951 22 C951 24,951 25,951 27 L951 27 C956 20,960 17,965 17 C967 17,969 18,971 20 C972 22,973 25,973 29 C973 33,972 37,971 41 C969 45,967 48,964 51 C961 53,958 54,954 54 C951 54,948 53,946 52 L944 60 C944 62,944 63,944 64 C944 65,944 66,945 66 C945 67,946 67,948 67 L948 69 L936 69 L945 30 Z M949 40 C948 42,948 43,948 43 C948 44,948 45,948 45 C948 47,949 49,949 50 C950 51,952 51,954 51 C955 51,956 51,957 50 C958 50,959 49,960 48 C961 47,962 46,963 45 C963 43,964 42,965 40 C965 38,966 36,966 34 C966 32,966 31,966 29 C966 26,966 24,965 23 C965 22,964 21,962 21 C961 21,960 22,958 22 C957 23,956 25,954 27 C953 29,952 30,951 32 C950 34,950 36,949 39 L949 40 Z" fill="#212121"/><path d="M1010 42 C1010 44,1009 46,1009 47 C1009 48,1009 49,1010 49 C1010 50,1011 50,1011 50 C1012 50,1013 50,1014 49 C1014 49,1016 48,1017 46 L1019 48 C1017 50,1015 52,1014 53 C1012 54,1010 54,1009 54 C1007 54,1006 54,1005 53 C1004 52,1004 50,1004 49 C1004 48,1004 46,1004 45 L1004 44 C1002 48,999 50,997 52 C995 53,993 54,990 54 C988 54,986 53,985 52 C984 51,983 49,983 46 C983 45,984 43,984 40 L987 30 C987 27,988 25,988 24 C988 23,988 22,987 22 C987 21,987 21,986 21 C985 21,984 21,983 22 C983 23,981 24,980 25 L978 23 C980 21,982 20,983 19 C984 18,985 18,986 18 C987 17,988 17,989 17 C990 17,992 18,993 19 C993 20,994 21,994 23 C994 25,994 28,993 31 L991 37 C991 39,990 40,990 41 C990 42,990 43,990 43 C990 44,990 45,990 45 C990 47,990 48,991 49 C991 50,992 50,993 50 C994 50,995 50,997 49 C998 48,999 47,1000 45 C1002 43,1003 42,1004 40 C1004 39,1005 37,1006 34 L1009 18 L1015 18 L1010 42 Z" fill="#212121"/><path d="M1045 46 C1043 49,1041 51,1039 52 C1037 53,1035 54,1033 54 C1028 54,1026 52,1026 46 C1026 45,1026 43,1026 41 L1030 22 L1024 22 L1025 20 C1026 20,1027 20,1028 20 C1029 20,1029 19,1030 19 C1030 19,1031 18,1031 17 C1032 17,1032 16,1033 15 C1033 14,1034 12,1034 9 L1039 9 L1037 18 L1048 18 L1048 22 L1037 22 L1033 36 C1033 39,1032 41,1032 43 C1032 44,1032 45,1032 45 C1032 49,1033 50,1036 50 C1037 50,1038 50,1039 49 C1040 48,1042 46,1043 44 L1045 46 Z" fill="#212121"/><path d="M1063 44 C1064 46,1064 48,1064 49 C1064 51,1064 53,1063 54 C1063 55,1062 57,1060 58 C1059 60,1057 61,1055 63 L1053 61 C1054 60,1055 59,1056 58 C1056 57,1056 56,1057 54 C1057 53,1057 52,1057 50 C1057 48,1057 46,1057 44 L1063 44 Z" fill="#212121"/><path d="M1099 38 C1099 37,1099 36,1099 36 C1098 36,1098 35,1098 35 C1097 35,1097 35,1096 35 L1094 35 L1090 53 L1083 53 L1093 11 C1093 10,1093 9,1093 8 C1094 7,1094 7,1094 6 C1094 5,1093 4,1093 4 C1092 3,1091 3,1089 3 L1090 1 L1099 1 L1101 1 L1094 33 L1095 33 C1097 33,1099 32,1101 31 C1104 29,1105 28,1107 26 C1108 25,1109 23,1109 22 C1109 21,1108 20,1106 20 L1107 18 L1119 18 L1119 20 C1117 22,1115 24,1113 25 L1104 33 L1107 46 C1108 47,1108 48,1108 49 C1109 49,1109 49,1109 50 C1109 50,1110 50,1110 50 C1111 50,1112 50,1113 49 C1113 48,1114 47,1116 46 L1118 48 C1115 50,1114 52,1112 53 C1111 54,1109 54,1108 54 C1106 54,1105 54,1104 53 C1103 52,1102 50,1102 48 L1099 38 Z" fill="#212121"/><path d="M1152 46 C1149 49,1147 51,1144 52 C1142 53,1139 54,1136 54 C1132 54,1130 53,1128 51 C1126 49,1125 46,1125 42 C1125 39,1125 36,1126 33 C1127 30,1129 27,1131 25 C1132 22,1135 20,1137 19 C1140 18,1143 17,1146 17 C1149 17,1151 18,1153 19 C1154 20,1155 22,1155 25 C1155 29,1153 32,1149 34 C1145 36,1139 37,1132 37 C1131 39,1131 40,1131 42 C1131 45,1132 47,1133 48 C1134 49,1135 50,1138 50 C1140 50,1142 50,1144 49 C1145 48,1147 46,1149 44 L1152 46 Z M1132 34 C1136 34,1139 34,1141 33 C1144 33,1145 32,1147 30 C1148 29,1149 27,1149 25 C1149 23,1148 22,1148 21 C1147 21,1146 20,1145 20 C1142 20,1140 21,1137 24 C1135 26,1133 30,1132 34 L1132 34 Z" fill="#212121"/><path d="M1174 27 C1177 23,1179 21,1181 19 C1183 18,1186 17,1188 17 C1190 17,1191 17,1192 17 L1191 26 L1187 26 C1187 25,1186 24,1186 24 C1186 23,1186 23,1185 22 C1185 22,1184 22,1184 22 C1183 22,1182 22,1181 23 C1180 24,1179 25,1177 27 C1176 28,1175 30,1174 31 C1174 33,1173 35,1172 37 L1169 53 L1163 53 L1168 29 C1168 28,1169 27,1169 26 C1169 25,1169 25,1169 24 C1169 23,1169 22,1168 22 C1168 21,1168 21,1167 21 C1166 21,1165 21,1164 22 C1164 23,1162 24,1161 25 L1159 23 C1161 21,1163 19,1165 18 C1166 18,1168 17,1170 17 C1171 17,1172 18,1173 19 C1174 20,1174 21,1174 22 C1174 24,1174 25,1174 26 L1174 27 Z" fill="#212121"/><path d="M1204 29 C1205 27,1205 25,1205 24 C1205 23,1205 22,1204 22 C1204 21,1204 21,1203 21 C1202 21,1201 21,1200 22 C1200 23,1198 24,1197 25 L1195 23 C1197 21,1199 19,1201 18 C1202 18,1204 17,1206 17 C1207 17,1208 18,1209 19 C1210 20,1211 21,1211 22 C1211 24,1210 25,1210 27 L1210 27 C1212 23,1215 21,1217 19 C1219 18,1221 17,1224 17 C1226 17,1228 18,1229 19 C1230 20,1231 22,1231 25 C1231 26,1230 29,1230 31 L1227 41 C1227 44,1226 46,1226 47 C1226 48,1226 49,1227 49 C1227 50,1228 50,1228 50 C1229 50,1230 50,1231 49 C1231 49,1233 48,1234 46 L1236 48 C1234 50,1232 52,1231 53 C1229 54,1227 54,1225 54 C1224 54,1223 53,1222 52 C1221 51,1220 50,1220 48 C1220 46,1221 44,1221 41 L1223 34 C1224 32,1224 30,1224 29 C1224 28,1224 27,1224 26 C1224 24,1224 23,1224 22 C1223 21,1222 21,1221 21 C1220 21,1219 22,1217 22 C1216 23,1215 24,1214 26 C1212 28,1211 29,1210 31 C1210 33,1209 35,1208 37 L1205 53 L1199 53 L1204 29 Z" fill="#212121"/><path d="M1268 46 C1265 49,1263 51,1260 52 C1258 53,1255 54,1252 54 C1248 54,1246 53,1244 51 C1242 49,1241 46,1241 42 C1241 39,1241 36,1242 33 C1243 30,1245 27,1247 25 C1248 22,1251 20,1253 19 C1256 18,1259 17,1262 17 C1265 17,1267 18,1269 19 C1270 20,1271 22,1271 25 C1271 29,1269 32,1265 34 C1261 36,1255 37,1248 37 C1247 39,1247 40,1247 42 C1247 45,1248 47,1249 48 C1250 49,1251 50,1254 50 C1256 50,1258 50,1260 49 C1261 48,1263 46,1265 44 L1268 46 Z M1248 34 C1252 34,1255 34,1257 33 C1260 33,1261 32,1263 30 C1264 29,1265 27,1265 25 C1265 23,1264 22,1264 21 C1263 21,1262 20,1261 20 C1258 20,1256 21,1253 24 C1251 26,1249 30,1248 34 L1248 34 Z" fill="#212121"/><path d="M1287 11 C1287 10,1287 9,1287 8 C1287 7,1287 7,1287 6 C1287 5,1287 5,1287 4 C1287 4,1286 4,1286 3 C1285 3,1285 3,1283 3 L1284 1 L1293 1 L1295 1 L1286 42 C1286 44,1285 46,1285 47 C1285 48,1285 49,1286 49 C1286 50,1287 50,1287 50 C1288 50,1289 50,1290 49 C1290 49,1292 48,1293 46 L1295 48 C1293 50,1291 52,1289 53 C1288 54,1286 54,1284 54 C1283 54,1281 53,1280 52 C1280 51,1279 50,1279 48 C1279 46,1279 44,1280 41 L1287 11 Z" fill="#212121"/><path d="M1318 35 C1318 26,1317 20,1314 14 C1311 9,1307 5,1301 3 L1302 0 C1309 2,1315 6,1318 12 C1322 19,1324 26,1324 35 C1324 44,1322 52,1318 58 C1315 64,1309 68,1302 70 L1301 67 C1307 65,1311 62,1314 56 C1317 51,1318 43,1318 35 L1318 35 Z" fill="#212121"/><path d="M1379 34 L1379 55 L1373 55 L1373 34 L1353 34 L1353 29 L1373 29 L1373 8 L1379 8 L1379 29 L1399 29 L1399 34 L1379 34 Z" fill="#212121"/><path d="M1430 52 L1427 54 L1424 53 L1434 11 C1434 9,1435 7,1435 6 C1435 5,1434 4,1434 4 C1433 3,1432 3,1430 3 L1431 1 L1440 1 L1442 1 L1436 26 L1436 26 C1439 23,1441 21,1443 19 C1445 18,1447 17,1449 17 C1452 17,1454 18,1455 20 C1457 22,1458 25,1458 29 C1458 33,1457 37,1455 41 C1454 45,1451 48,1448 51 C1446 53,1442 54,1439 54 C1435 54,1433 53,1430 52 L1430 52 Z M1433 40 C1433 42,1433 44,1433 45 C1433 47,1433 49,1434 50 C1435 51,1436 51,1438 51 C1439 51,1440 51,1441 51 C1442 50,1443 50,1444 49 C1445 48,1446 47,1447 46 C1447 45,1448 43,1449 41 C1450 39,1450 37,1451 35 C1451 33,1451 31,1451 29 C1451 26,1451 24,1450 23 C1449 22,1448 21,1447 21 C1445 21,1444 21,1443 22 C1442 23,1441 24,1439 26 C1438 28,1437 30,1436 32 C1435 33,1434 36,1434 39 L1433 40 Z" fill="#212121"/><path d="M1482 3 L1480 10 L1474 10 L1475 3 L1482 3 Z M1470 29 C1470 26,1471 24,1471 23 C1471 22,1470 21,1470 21 C1469 20,1468 20,1467 20 L1467 18 L1476 17 L1478 17 L1473 42 C1473 44,1472 46,1472 47 C1472 48,1472 49,1473 49 C1473 50,1474 50,1474 50 C1475 50,1476 50,1477 49 C1477 49,1479 48,1480 46 L1482 48 C1480 50,1478 52,1476 53 C1475 54,1473 54,1471 54 C1470 54,1469 53,1468 52 C1467 51,1466 50,1466 48 C1466 46,1467 44,1467 41 L1470 29 Z" fill="#212121"/><path d="M1516 20 L1520 17 L1522 18 L1517 42 C1516 44,1516 46,1516 47 C1516 48,1516 49,1516 49 C1517 50,1517 50,1518 50 C1519 50,1520 50,1520 49 C1521 49,1522 48,1524 46 L1526 48 C1524 50,1522 52,1520 53 C1519 54,1517 54,1515 54 C1514 54,1513 54,1512 53 C1511 52,1510 50,1510 49 C1510 48,1511 46,1511 45 L1511 44 C1508 48,1506 50,1504 52 C1502 53,1500 54,1497 54 C1495 54,1493 53,1491 51 C1490 49,1489 46,1489 42 C1489 38,1490 34,1491 30 C1493 26,1495 23,1498 21 C1501 18,1504 17,1508 17 C1509 17,1511 17,1512 18 C1514 18,1515 19,1516 20 L1516 20 Z M1513 31 C1513 30,1514 29,1514 28 C1514 27,1514 27,1514 26 C1514 24,1513 22,1513 21 C1512 21,1510 20,1508 20 C1506 20,1504 21,1502 23 C1500 25,1498 28,1497 32 C1496 35,1495 39,1495 42 C1495 45,1496 47,1496 48 C1497 49,1498 50,1500 50 C1502 50,1503 49,1505 48 C1506 47,1508 44,1509 42 C1511 39,1512 36,1513 32 L1513 31 Z" fill="#212121"/><path d="M1555 27 C1554 25,1554 23,1552 22 C1551 21,1550 20,1547 20 C1545 20,1544 21,1542 22 C1541 23,1541 24,1541 26 C1541 27,1541 27,1541 28 C1541 29,1542 30,1543 30 C1544 31,1545 32,1547 33 C1549 34,1550 35,1551 36 C1552 37,1553 38,1553 38 C1554 39,1554 40,1554 41 C1554 42,1555 43,1555 44 C1555 46,1554 48,1553 49 C1552 51,1550 52,1548 53 C1546 54,1544 54,1541 54 C1539 54,1537 54,1535 54 C1533 53,1531 53,1529 52 L1531 44 L1533 44 C1534 46,1534 48,1535 49 C1537 51,1539 51,1541 51 C1544 51,1545 51,1547 50 C1548 49,1549 47,1549 45 C1549 44,1548 43,1548 42 C1548 41,1547 41,1546 40 C1545 39,1544 38,1542 37 C1540 36,1539 35,1538 34 C1537 33,1536 32,1536 31 C1535 30,1535 28,1535 27 C1535 25,1535 23,1536 22 C1537 20,1539 19,1541 18 C1543 18,1545 17,1547 17 C1550 17,1552 17,1554 18 C1556 18,1557 18,1559 19 L1558 27 L1555 27 Z" fill="#212121"/><path d="M1582 35 C1582 26,1581 20,1578 14 C1575 9,1571 5,1565 3 L1566 0 C1573 2,1579 6,1582 12 C1586 19,1588 26,1588 35 C1588 44,1586 52,1582 58 C1579 64,1573 68,1566 70 L1565 67 C1571 65,1575 62,1578 56 C1581 51,1582 43,1582 35 L1582 35 Z" fill="#212121"/></svg></span></p>
<p class="p_Text"><span class="f_Text">where:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">activation</span><span class="f_li"> = activation function, set in parameters</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">input</span><span class="f_li"> = an array of source data</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">kernel</span><span class="f_li"> = a weight matrix</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">dot</span><span class="f_li"> = a vector multiplication operation</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">bias</span><span class="f_li"> = a displacement element</span></li>
</ul>
<p class="p_Text"><span class="f_Text" style="font-style: italic;">Dense</span><span class="f_Text"> provides parameters to control the neural layer creation process:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">units</span><span class="f_li"> – the dimension of the output space (the number of neurons in the layer);</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">activation</span><span class="f_li"> – the activation function used;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">use_bias</span><span class="f_li"> – is an optional parameter that indicates whether to use a vector of displacement elements;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">kernel_initializer</span><span class="f_li"> – the method of initializing the matrix of weights;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">bias_initializer</span><span class="f_li"> – a method for initializing a vector of displacement elements;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">kernel_regularizer</span><span class="f_li"> – a weight matrix regularization method;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">bias_regularizer</span><span class="f_li"> – a method for regularizing the displacement vector;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">activity_regularizer</span><span class="f_li"> – a method of regularizing the activation function;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">kernel_constraint</span><span class="f_li"> – a weight matrix restriction function;</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">bias_constraint</span><span class="f_li"> – a displacement vector restriction function.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">Please note that you cannot change the settings after the first access to the layer.</span></p>
<p class="p_Text"><span class="f_Text">In addition to the above parameters, </span><span class="f_Text" style="font-style: italic;">Dense</span><span class="f_Text"> can take an </span><span class="f_Text" style="font-style: italic;">input_shape</span><span class="f_Text"> parameter that indicates the size of the input array. This parameter is valid only for the first layer of the neural network. When this parameter is used, an input layer is created to be inserted in front of the current layer. The operation can be considered as an equivalent to explicitly defining the input layer.</span></p>
<p class="p_Text"><span class="f_Text">We'll start implementing our first neural network model by copying our script template into a new </span><span class="f_Text" style="font-style: italic;">perceptron.py</span><span class="f_Text"> file. In the created file, we will create the first model with one hidden layer of 40 neurons and 2 neurons in the results layer. In the hidden layer, we'll use </span><span class="f_Text" style="font-style: italic;">Swish</span><span class="f_Text"> as an activation function. The neurons in the output layer will be activated by the hyperbolic tangent.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Create&nbsp;a&nbsp;neural&nbsp;network&nbsp;model</span>
<br><span class="f_CodeExample">model1&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">In theory, this is enough to start training the model. However, we study the operation of various models and want to understand the influence of changing the neural network architecture on the model ability to learn and generalize the initial data. So I've added two more models. One model has two additional hidden layers. The result is a model with three hidden layers. All three hidden layers are completely identical: they have 40 elements each and are activated by the </span><span class="f_Text" style="font-style: italic;">Swish</span><span class="f_Text"> function. The first and last layers remain unchanged.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Create&nbsp;a&nbsp;model&nbsp;with&nbsp;three&nbsp;hidden&nbsp;layers</span>
<br><span class="f_CodeExample">model2&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The following steps should be repeated for each model. First, let's prepare the model for training using the </span><span class="f_Text" style="font-style: italic;">compile</span><span class="f_Text"> method.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">model2.</span><span class="f_CodeExample" style="color: #ff0000;">compile</span><span class="f_CodeExample">(optimizer=</span><span class="f_CodeExample" style="color: #008080;">'Adam'</span><span class="f_CodeExample">,&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss=</span><span class="f_CodeExample" style="color: #008080;">'mean_squared_error'</span><span class="f_CodeExample">,&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics=[</span><span class="f_CodeExample" style="color: #008080;">'accuracy'</span><span class="f_CodeExample">])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After that, we will start the model training process and save the trained model.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">history2&nbsp;=&nbsp;model2.fit(train_data,&nbsp;train_target,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;epochs=</span><span class="f_CodeExample" style="color: #008100;">500</span><span class="f_CodeExample">,&nbsp;batch_size=</span><span class="f_CodeExample" style="color: #008100;">1000</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;callbacks=[callback],</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose=</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;validation_split=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0.2</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffle=</span><span class="f_CodeExample" style="color: #ff0000;">True</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">model2.save(os.path.join(path,</span><span class="f_CodeExample" style="color: #008080;">'perceptron2.h5'</span><span class="f_CodeExample">))</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">We will build the third model on the basis of the second model with the addition of regularization. For each neural layer, we will specify in the </span><span class="f_Text" style="font-style: italic;">kernel_regularizer</span><span class="f_Text"> parameter the </span><span class="f_Text" style="font-style: italic;">keras.regularizers.l1_l2</span><span class="f_Text"> class object with the </span><span class="f_Text" style="font-style: italic;">L1</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">L2</span><span class="f_Text">-regularization parameters. As you can see from the class name, we'll be using </span><span class="f_Text" style="font-style: italic;">ElasticNet</span><span class="f_Text">.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Add&nbsp;regularization&nbsp;to&nbsp;the&nbsp;model&nbsp;with&nbsp;three&nbsp;hidden&nbsp;layers</span>
<br><span class="f_CodeExample">model3&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Next, we'll compile and train the model. All three models use identical training parameters. This will make it possible to directly assess the impact of the model architecture on the learning outcome. At the same time, we will eliminate the influence of other factors as much as possible.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">model3.</span><span class="f_CodeExample" style="color: #ff0000;">compile</span><span class="f_CodeExample">(optimizer=</span><span class="f_CodeExample" style="color: #008080;">'Adam'</span><span class="f_CodeExample">,&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loss=</span><span class="f_CodeExample" style="color: #008080;">'mean_squared_error'</span><span class="f_CodeExample">,&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics=[</span><span class="f_CodeExample" style="color: #008080;">'accuracy'</span><span class="f_CodeExample">])</span>
<br><span class="f_CodeExample">history3&nbsp;=&nbsp;model3.fit(train_data,&nbsp;train_target,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;epochs=</span><span class="f_CodeExample" style="color: #008100;">500</span><span class="f_CodeExample">,&nbsp;batch_size=</span><span class="f_CodeExample" style="color: #008100;">1000</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;callbacks=[callback],</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose=</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;validation_split=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0.2</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffle=</span><span class="f_CodeExample" style="color: #ff0000;">True</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">model3.save(os.path.join(path,</span><span class="f_CodeExample" style="color: #008080;">'perceptron3.h5'</span><span class="f_CodeExample">))</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Since we are training not one but three models in this script, we also need to correct the visualization unit. Let's display the training results of all three models on one graph. This will demonstrate differences in the training and validation process. We will make changes to the blocks for constructing both graphs.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Plot&nbsp;the&nbsp;training&nbsp;results&nbsp;of&nbsp;the&nbsp;three&nbsp;models</span>
<br><span class="f_CodeExample">plt.figure()</span>
<br><span class="f_CodeExample">plt.plot(history1.history[</span><span class="f_CodeExample" style="color: #008080;">'loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history1.history[</span><span class="f_CodeExample" style="color: #008080;">'val_loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history2.history[</span><span class="f_CodeExample" style="color: #008080;">'loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history2.history[</span><span class="f_CodeExample" style="color: #008080;">'val_loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history3.history[</span><span class="f_CodeExample" style="color: #008080;">'loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;3&nbsp;hidden&nbsp;layers&nbsp;vs&nbsp;regularization'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history3.history[</span><span class="f_CodeExample" style="color: #008080;">'val_loss'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;3&nbsp;hidden&nbsp;layer&nbsp;vs&nbsp;regularization'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.ylabel(</span><span class="f_CodeExample" style="color: #008080;">'$MSE$&nbsp;$Loss$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.xlabel(</span><span class="f_CodeExample" style="color: #008080;">'$Epochs$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.title(</span><span class="f_CodeExample" style="color: #008080;">'Dynamic&nbsp;of&nbsp;Models&nbsp;train'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.legend(loc=</span><span class="f_CodeExample" style="color: #008080;">'lower&nbsp;left'</span><span class="f_CodeExample">)</span></p>
</td>
</tr>
</table>
</div>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">plt.figure()</span>
<br><span class="f_CodeExample">plt.plot(history1.history[</span><span class="f_CodeExample" style="color: #008080;">'accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history1.history[</span><span class="f_CodeExample" style="color: #008080;">'val_accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history2.history[</span><span class="f_CodeExample" style="color: #008080;">'accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history2.history[</span><span class="f_CodeExample" style="color: #008080;">'val_accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history3.history[</span><span class="f_CodeExample" style="color: #008080;">'accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Train&nbsp;3&nbsp;hidden&nbsp;layers\nvs&nbsp;regularization'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.plot(history3.history[</span><span class="f_CodeExample" style="color: #008080;">'val_accuracy'</span><span class="f_CodeExample">],</span><br>
<span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;label=</span><span class="f_CodeExample" style="color: #008080;">'Validation&nbsp;3&nbsp;hidden&nbsp;layer\nvs&nbsp;regularization'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.ylabel(</span><span class="f_CodeExample" style="color: #008080;">'$Accuracy$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.xlabel(</span><span class="f_CodeExample" style="color: #008080;">'$Epochs$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.title(</span><span class="f_CodeExample" style="color: #008080;">'Dynamic&nbsp;of&nbsp;Models&nbsp;train'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.legend(loc=</span><span class="f_CodeExample" style="color: #008080;">'upper&nbsp;left'</span><span class="f_CodeExample">)</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After training, our template tests the model performance on a test sample. Here, we also have to test three models under similar conditions. I'll skip the test sample loading block, as it moved from the template unchanged. Here is just a code for directly testing models.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Check&nbsp;the&nbsp;results&nbsp;of&nbsp;models&nbsp;on&nbsp;a&nbsp;test&nbsp;sample</span>
<br><span class="f_CodeExample">test_loss1,&nbsp;test_acc1&nbsp;=&nbsp;model1.evaluate(test_data,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_target,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose=</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">)&nbsp;</span>
<br><span class="f_CodeExample">test_loss2,&nbsp;test_acc2&nbsp;=&nbsp;model2.evaluate(test_data,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_target,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose=</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">)&nbsp;</span>
<br><span class="f_CodeExample">test_loss3,&nbsp;test_acc3&nbsp;=&nbsp;model3.evaluate(test_data,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;test_target,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;verbose=</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">)</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The test results in the template were published in a journal. Now we have the results of testing three models. It will be more efficient to compare the results on the graph. We will use the </span><span class="f_Text" style="font-style: italic;">Matplolib</span><span class="f_Text"> library to build graphs.</span></p>
<p class="p_Text"><span class="f_Text">In this case, we will not display the dynamics of the process, as before, but compare the values. Therefore, it will be more convenient to use a column chart to display values. The library offers the </span><span class="f_Text" style="font-style: italic;">bar</span><span class="f_Text"> method for constructing diagrams. This method takes two arrays in its parameters: in the first, we will specify the labels of the compared parameters, and in the second, their values. To complete the picture, let's add the title of the graph and the vertical axis using the </span><span class="f_Text" style="font-style: italic;">title</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">ylabel</span><span class="f_Text"> methods, respectively.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">plt.figure()</span>
<br><span class="f_CodeExample">plt.bar(</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;[</span><span class="f_CodeExample" style="color: #008080;">'1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008080;">'3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #008080;">'3&nbsp;hidden&nbsp;layers\nvs&nbsp;regularization'</span><span class="f_CodeExample">],</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;[test_loss1,test_loss2,test_loss3])</span>
<br><span class="f_CodeExample">plt.ylabel(</span><span class="f_CodeExample" style="color: #008080;">'$MSE$&nbsp;$Loss$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.title(</span><span class="f_CodeExample" style="color: #008080;">'Result&nbsp;of&nbsp;test'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;</span>
<br><span class="f_CodeExample">plt.figure()</span>
<br><span class="f_CodeExample">plt.bar(</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;[</span><span class="f_CodeExample" style="color: #008080;">'1&nbsp;hidden&nbsp;layer'</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008080;">'3&nbsp;hidden&nbsp;layers'</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #008080;">'3&nbsp;hidden&nbsp;layers\nvs&nbsp;regularization'</span><span class="f_CodeExample">],</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;[test_acc1,test_acc2,test_acc3])</span>
<br><span class="f_CodeExample">plt.ylabel(</span><span class="f_CodeExample" style="color: #008080;">'$Accuracy$'</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">plt.title(</span><span class="f_CodeExample" style="color: #008080;">'Result&nbsp;of&nbsp;test'</span><span class="f_CodeExample">)</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">We will see how the script works a little later. In the next chapter, we'll prepare data for training and testing models.</span></p>

</div>

</body>
</html>
