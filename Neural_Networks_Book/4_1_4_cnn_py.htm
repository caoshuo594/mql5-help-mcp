<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <title>4.1.4 Implementing a convolutional model in Python</title>
  <meta name="keywords" content="" />
  <link type="text/css" href="default.css" rel="stylesheet" />

   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>


</head>

<body style="background-color:#FFFFFF; font-family:'Trebuchet MS',Tahoma,Arial,Helvetica,sans-serif; margin:0px;">



<table width="100%" height="49"  border="0" cellpadding="0" cellspacing="0" style="margin-top:0px; background-color:#1660af;">
  <tr>
    <td></td>
    <td valign="middle">
      <table style="margin-top:4px; margin-bottom:5px;" width="100%"  border="0" cellspacing="0" cellpadding="5">
        <tr valign="middle">
          <td class="nav">
<a class="h_m" href="index.htm">          Neural Networks for Algorithmic Trading with MQL5 </a> / <a class="h_m" href="4_main_layer_types.htm"> 4. Basic types of neural layers </a> / <a class="h_m" href="4_1_cnn.htm"> 4.1 Convolutional neural networks </a>/ 4.1.4 Implementing a convolutional model in Python
          </td>
          <td width="70" align="right">
          <a href="4_1_3_cnn_opencl.htm"><img style="vertical-align:middle;" src="previous.png" alt="?????" width="27" height="27" border=0></a>&nbsp;
          <a href="4_1_5_cnn_realizations_comparison.htm"><img style="vertical-align:middle;" src="next.png" alt="??????" width="27" height="27" border="0"></a>
          </td>
        </tr>
      </table>
    </td>
    <td width="5"></td>
  </tr>
</table>



<div id="help">
<p class="p_H2"><span class="f_H2">4.1.4 Implementing a convolutional model in Python</span></p>
<p class="p_Text"><span class="f_Text">We will implement the convolutional models in the Python language using the tools provided by the </span><span class="f_Text" style="font-style: italic;">Keras</span><span class="f_Text"> library from </span><span class="f_Text" style="font-style: italic;">TensorFlow</span><span class="f_Text">. This library offers several options for convolutional layers. First of all, these are the basic versions of convolutional layers:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">Conv1D</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">Conv2D</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">Conv3D</span></li>
</ul>
<p class="p_Text"><span class="f_Text">From the names of the objects representing convolutional layers, it can be inferred that they are intended for processing input data of various dimensions.</span></p>
<p class="p_Text"><span class="f_Text">The </span><span class="f_Text" style="font-style: italic;">Conv1D</span><span class="f_Text"> class objects create the core of the convolution that collapses with the original data in one dimension to create an output tensor. It is important to understand and not to get confused. The initial data is convoluted in one dimension, but the initial data supplied to the neural layer input must be in the form of a three-dimensional tensor. The first dimension determines the size of the package of the data (</span><span class="f_Text" style="font-style: italic;">batch size</span><span class="f_Text">) being processed. The second is measuring convolution. The third dimension contains the initial data for convolution.</span></p>
<p class="p_Text"><span class="f_Text">As a result of data processing, the layer also returns a 3D tensor. The first dimension remains the same; it is equal to the size of the data package being processed. The second dimension varies depending on the specified convolution parameters. The third dimension will be equal to the specified number of filters used.</span></p>
<p class="p_Text"><span class="f_Text">It should be understood that each filter applies to all initial data. At one time, the initial data is processed in the size of the third dimension multiplied by the size of the convolution window. This is a slight difference from our implementation of the convolutional layer in MQL5. There, we defined the convolution window as the number of elements, while here, the convolution window determines the number of elements in the second dimension of the three-dimensional tensor of input data.</span></p>
<p class="p_Text"><span class="f_Text">One filter returns one value for each convolution window. Since the entire third dimension is involved in the convolution process, we get one element from each filter. As a result, the size of the third dimension of the output tensor changes by the number of filters used.</span></p>
<p class="p_Text"><span class="f_Text">Like a fully connected layer, the convolutional layer class offers a fairly wide range of parameters for fine-tuning the operation. Let's take a look at them.</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">filters</span><span class="f_li"> – the number of filters used in the bundle.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">kernel_size</span><span class="f_li"> – one-dimensional convolution window size.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">strides</span><span class="f_li"> – the size of the convolution step.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">padding</span><span class="f_li"> – one of the following values is allowed: &quot;</span><span class="f_li" style="font-style: italic;">valid</span><span class="f_li">&quot;, &quot;</span><span class="f_li" style="font-style: italic;">same</span><span class="f_li">&quot; or &quot;</span><span class="f_li" style="font-style: italic;">causal</span><span class="f_li">&quot; (case-insensitive); &quot;</span><span class="f_li" style="font-style: italic;">valid</span><span class="f_li">&quot; means no indentation; &quot;</span><span class="f_li" style="font-style: italic;">same</span><span class="f_li">&quot; causes the input data to be evenly filled with zeros to obtain an output size equal to the input size; &quot;</span><span class="f_li" style="font-style: italic;">causal</span><span class="f_li">&quot; leads to the emergence of causal (extended) changes, for example, </span><span class="f_li" style="font-style: italic;">output [t]</span><span class="f_li"> does not depend from </span><span class="f_li" style="font-style: italic;">input [t+1:]</span><span class="f_li">. It's useful when modeling temporal data, where the model must not violate the temporal order.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">data_format</span><span class="f_li"> – one of the following values is allowed: “</span><span class="f_li" style="font-style: italic;">channels_last</span><span class="f_li">” or “</span><span class="f_li" style="font-style: italic;">channels_first</span><span class="f_li">”; determines which dimension of the input tensor contains data for convolution; the default is “</span><span class="f_li" style="font-style: italic;">channels_last</span><span class="f_li">”.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">dilation_rate</span><span class="f_li"> – used for advanced convolution and determines the expansion rate.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">groups</span><span class="f_li"> – the number of groups into which the input is divided along the channel axis; each group is collapsed separately using filters, and the output is a combination of all results along the channel axis.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">activation</span><span class="f_li"> – activation function.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">use_bias</span><span class="f_li"> – indicates whether to use a bias vector.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">kernel_initializer</span><span class="f_li"> – sets a method for initializing the weight matrix.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">bias_initializer</span><span class="f_li"> – sets the method for initializing the displacement vector.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">kernel_regularizer</span><span class="f_li"> – indicates a method for regularizing the weight matrix.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">bias_regularizer</span><span class="f_li"> – indicates a method for regularizing the displacement vector.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">activity_regularizer</span><span class="f_li"> – indicates a method for regularizing results.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">kernel_constraint</span><span class="f_li"> – specifies the restriction function for the weight matrix.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">bias_constraint</span><span class="f_li"> – specifies the constraint function for the displacement vector.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">For timeseries, it is usually suggested to use a one-dimensional Conv1D convolution. Convolution is carried out by time intervals. At the same time, each filter checks for its own pattern in a specific time interval. In relation to solving our problem, filters will assess the status of all indicators used within the number of candles specified by the </span><span class="f_Text" style="font-style: italic;">strides</span><span class="f_Text"> parameter. The process of convolution, like the neurons of a fully connected layer, does not assess the mutual influence of individual components of the initial data. It only assesses the similarity of the initial data with a given pattern. Of course, we don't explicitly define these patterns when constructing the neural network. We select them during the training process. However, it is assumed that during practical application, these patterns will remain static between retraining periods.</span></p>
<p class="p_Text"><span class="f_Text">True, convolutional layers are more resistant to various distortions of the initial data due to the fact that small individual blocks are studied meticulously. However, it may be necessary to study the patterns of individual indicators. To solve this problem, we may need to use convolutional layers of a different dimension.</span></p>
<p class="p_Text"><span class="f_Text">For example, Conv2D objects operate with convolutions with input data in two dimensions. At the same time, it should be understood that the difference between one-dimensional and two-dimensional convolutional layers goes beyond just their names. Objects in a two-dimensional convolutional layer expect a four-dimensional tensor at the input. By analogy with the </span><span class="f_Text" style="font-style: italic;">Conv1D</span><span class="f_Text"> tensor, the first dimension determines the batch size, the second and third dimensions determine the convolution dimensions and the fourth dimension contains the initial data for convolution. Here arises a valid question: where do we obtain the data for another dimension? How do we divide our initial data set into four dimensions? We need to translate our raw data from a flat table to a voluminous table. The simplest solution is on the surface. We say that the depth of the table of the initial data is 1. Before declaring the two-dimensional neural layer, let's change the dimensionality of the tensor input to the Conv2D convolutional layer to a four-dimensional one by specifying a size of 1 for the fourth dimension.</span></p>
<p class="p_Text"><span class="f_Text">Note that since the fourth dimension is 1, the length of the input data vector for convolution is 1. Therefore, for the convolution process to be effective, the convolution window needs to be greater than 1 in at least one dimension.</span></p>
<p class="p_Text"><span class="f_Text">We will not dwell too much on the parameters of the Conv2D convolutional layer, since they are identical to the parameters of a one-dimensional array. The only differences are in the </span><span class="f_Text" style="font-style: italic;">kernel_size</span><span class="f_Text">, </span><span class="f_Text" style="font-style: italic;">strides</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">dilation_rate</span><span class="f_Text"> parameters, which, in addition to a scalar value, can take a vector of two elements. Each element of such a vector contains parameter values for the corresponding dimension. At the same time, these parameters can take scalar values. In this case, the specified value will be used for both dimensions.</span></p>
<p class="p_Text"><span class="f_Text">For more complex architectural solutions for neural networks, it may be necessary to use Conv3D 3D convolutional layers. Their usage can be justified, for example, in building arbitrage trading systems, where a separate dimension might be needed to segregate input data by instruments.</span></p>
<p class="p_Text"><span class="f_Text">Just like in the case of a two-dimensional convolutional layer, using three-dimensional space requires increasing the dimensionality of the input data. A five-dimensional tensor is expected at the Conv3D input.</span></p>
<p class="p_Text"><span class="f_Text">The parameters of the Conv3D class, however, are inherited from the aforementioned classes with minimal changes. The only difference is in the size of the vectors of the convolution window and its pitch.</span></p>
<p class="p_Text"><span class="f_Text">Attention should be paid to another feature of the convolution process. When performing operations, it is possible to both reduce the size of the data tensor (data compression) and increase it. The first approach is useful when dealing with large datasets, where it's necessary to extract a specific component from the overall volume of input information. This is frequently employed in computer vision tasks, where in high-resolution images, each pixel represents an individual value within the overall tensor of input data.</span></p>
<p class="p_Text"><span class="f_Text">The second approach, increasing the dimensionality, can be beneficial when there's an insufficient amount of input data. In such cases, a small volume of input data needs to be split into separate components while searching for non-obvious dependencies.</span></p>
<p class="p_Text"><span class="f_Text">It should be noted that this is not a complete list of convolutional layers offered by the Keras library. But it is beyond the scope of this book to describe all the library's features. You can always check them out on the library <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers" target="_blank" rel="external" class="weblink" title="TensorFlow Layers">website</a>. There you can also find the latest version of the library and instructions for installing and using it.</span></p>
<p class="p_Text"><span class="f_Text">Just like convolutional layers, the Keras library offers several class options for a pooling layer. Among them are:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">AvgPool1D</span><span class="f_li"> – one-dimensional data averaging.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">AvgPool2D</span><span class="f_li"> – two-dimensional data averaging.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">AvgPool3D</span><span class="f_li"> – three-dimensional data averaging.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">MaxPool1D</span><span class="f_li"> – one-dimensional extraction of the maximum value.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">MaxPool2D</span><span class="f_li"> – two-dimensional extraction of the maximum value.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic; font-weight: bold;">MaxPool3D</span><span class="f_li"> – three-dimensional extraction of the maximum value.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">All of these pooling layers have the same set of parameters:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">pool_size</span><span class="f_li"> – an integer number or vector of integers, determines the window size.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">strides</span><span class="f_li"> – an integer number or vector of integers, determines the window pitch.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">padding</span><span class="f_li"> – means one of the following values is allowed: &quot;</span><span class="f_li" style="font-style: italic;">valid</span><span class="f_li">&quot;, &quot;</span><span class="f_li" style="font-style: italic;">same</span><span class="f_li">&quot; or &quot;</span><span class="f_li" style="font-style: italic;">causal</span><span class="f_li">&quot; (case-insensitive); &quot;</span><span class="f_li" style="font-style: italic;">valid</span><span class="f_li">&quot; means no indentation; &quot;</span><span class="f_li" style="font-style: italic;">same</span><span class="f_li">&quot; – causes the source data to be evenly filled with zeros to obtain an output size equal to the input size.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">data_format</span><span class="f_li"> – one of the following values is allowed: &quot;</span><span class="f_li" style="font-style: italic;">channels_last</span><span class="f_li">&quot; or &quot;</span><span class="f_li" style="font-style: italic;">channels_first</span><span class="f_li">&quot;; determines which dimension of the input tensor contains data for convolution; the default is &quot;</span><span class="f_li" style="font-style: italic;">channels_last</span><span class="f_li">&quot;.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">We will also implement convolutional neural network models in our <a href="3_5_py_struct.htm" class="topiclink">template</a>. Just like when testing perceptron models, we will create three neural network models with different architectures and compare the results of their training. Therefore, for implementation, we will take the previously created file </span><span class="f_Text" style="font-style: italic;"><a href="3_8_pr_py.htm" class="topiclink">perceptron.py</a></span><span class="f_Text"> and create a copy of it called </span><span class="f_Text" style="font-style: italic;">convolution.py</span><span class="f_Text">. In this created file, we will replace the model declaration blocks. </span></p>
<p class="p_Text"><span class="f_Text">First, we will create a perceptron with three hidden layers and weight matrix regularization. It will serve as a basis for comparing the performance of convolutional neural networks to the results of training a fully connected perceptron.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Create&nbsp;a&nbsp;perceptron&nbsp;model&nbsp;with&nbsp;three&nbsp;hidden&nbsp;layers&nbsp;and&nbsp;regularization</span>
<br><span class="f_CodeExample">model1&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">This model has 9802 parameters. The screenshot below shows the structure of the neural network we created. In the first column of the table, the name and type of the neural layer are indicated, while in the second column, the tensor dimensionality of the results for each layer is specified. Note that the first dimension is not set; </span><span class="f_Text" style="font-style: italic;">None</span><span class="f_Text"> is specified instead of the size. This means that this dimension is not strictly defined and can be of variable length. This dimension is set by the </span><span class="f_Text" style="font-style: italic;">batch size</span><span class="f_Text"> of the data patch. The third column shows the number of parameters in the weight matrix for each layer.</span></p>
<p class="p_Text"><span class="f_Text">In the second model, we will insert a one-dimensional </span><span class="f_Text" style="font-style: italic;">Conv1D</span><span class="f_Text"> convolution layer with 8 filters immediately after the initial data, and specify the convolution window and step as 1. Such a layer will roll up all specified indicators within a single candlestick. In doing so, let's not forget to change the dimensionality of the input data tensor from two-dimensional to three-dimensional.</span></p>
<p class="p_Text"><span class="f_Text">Note that although we're transferring data to a 3D tensor, we specify two dimensions in the </span><span class="f_Text" style="font-style: italic;">Reshape</span><span class="f_Text"> layer parameters. This is due to the fact that the first dimension of the tensor is variable and is set by the </span><span class="f_Text" style="font-style: italic;">batch size</span><span class="f_Text"> of the input data batch.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:665px"><img class="help" alt="Perceptron structure" title="Perceptron structure" width="665" height="300" style="width:665px;height:300px;border:none" src="perceptron_summary.png"/><p style="text-align:center"><span class="f_ImageCaption">Perceptron structure</span></p></div></div>
<p class="p_Text"><span class="f_Text">And one more thing. The dimensional vector passed in the parameters of the </span><span class="f_Text" style="font-style: italic;">Reshape</span><span class="f_Text"> class contains &#8722;1 in the first dimension. This tells the class to independently calculate the size of this dimension based on the size of the original data tensor and the specified dimensions of other dimensions.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Add&nbsp;a&nbsp;1D&nbsp;convolutional&nbsp;layer&nbsp;to&nbsp;the&nbsp;model</span>
<br><span class="f_CodeExample">model2&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Reformat&nbsp;the&nbsp;tensor&nbsp;into&nbsp;three-dimensional.</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;We&nbsp;indicate&nbsp;2&nbsp;dimensions,&nbsp;because&nbsp;The&nbsp;3rd&nbsp;dimension&nbsp;is&nbsp;determined&nbsp;by&nbsp;the&nbsp;packet&nbsp;size</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Reshape((-</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">4</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Convolutional&nbsp;layer&nbsp;with&nbsp;8&nbsp;filters</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Conv1D(</span><span class="f_CodeExample" style="color: #008100;">8</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">,activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Behind the convolutional layer, we will place a one-dimensional subsample layer with a choice of the maximum </span><span class="f_Text" style="font-style: italic;">MaxPool1D value. </span><span class="f_Text">As mentioned above, the convolutional layer operates with three-dimensional tensors. At the same time, the subsequent fully connected layers work with two-dimensional tensors. Therefore, for the proper functioning of fully connected layers, we need to return the data to a two-dimensional dimensionality. To do this, we will use the neural layer of the </span><span class="f_Text" style="font-style: italic;">Flatten</span><span class="f_Text"> class.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">&nbsp;</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Pooling&nbsp;layer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.MaxPooling1D(</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">,strides=</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Reformat&nbsp;the&nbsp;tensor&nbsp;into&nbsp;a&nbsp;two-dimensional&nbsp;one&nbsp;for&nbsp;fully&nbsp;connected&nbsp;layers</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Flatten(),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Note: In the initial data, each candlestick is described by four values. The use of eight filters increases the dimensionality of the processed tensor. As a result, the model with a one-dimensional convolutional layer already contains 15,922 parameters.</span></p>
<p class="p_Text"><span class="f_Text">In the third model, we will replace a 1 one-dimensional convolution layer with a two-dimensional one. As a result, we will change the pooling layer and the data dimension. As mentioned above, we will set the fourth dimension to 1. We can now control the size of the convolution window in two dimensions: time and indicator. Since we would like to assess different patterns in the readings of each individual indicator, we will specify the size of the convolution window in the first temporal dimension as 3 (evaluating patterns from 3 consecutive candlesticks), and the size of the window in the second dimension of indicators as 1. This will allow us to identify patterns in the movement of each indicator separately. The pitch of the convolution window in both directions will be set to 1.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:665px"><img class="help" alt="Neural network structure with a one-dimensional convolutional layer" title="Neural network structure with a one-dimensional convolutional layer" width="665" height="525" style="width:665px;height:525px;border:none" src="conv1d_summary.png"/><p style="text-align:center"><span class="f_ImageCaption">Neural network structure with a one-dimensional convolutional layer</span></p></div></div>
<p class="p_Text"><span class="f_Text">With these parameters, the first dimension (time dimension) will decrease by two elements as a result of the convolution operations. The second dimension (dimension of indicators) will remain unchanged since the convolution window and its pitch in this dimension are 1. At the same time, we will increase the third dimension, and it will become equal to the number of filters. Let me remind you that before the convolution operation, the third dimension was equal to 1. As a result of all iterations, the number of network parameters increased to 50,794. The structure of the new neural network is presented below. As you can see, the convolution layer has only 32 parameters. Such an increase in the number of network parameters is due to the enlargement of the tensor size after the convolution operation for the reasons mentioned above. This can be seen from the number of parameters in the first fully connected layer after convolution.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">#&nbsp;Replace&nbsp;the&nbsp;convolutional&nbsp;layer&nbsp;in&nbsp;the&nbsp;model&nbsp;with&nbsp;a&nbsp;two-dimensional&nbsp;one</span>
<br><span class="f_CodeExample">model3&nbsp;=&nbsp;keras.Sequential([keras.Input(shape=inputs),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Reformat&nbsp;the&nbsp;tensor&nbsp;into&nbsp;a&nbsp;four-dimensional&nbsp;one.</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#We&nbsp;indicate&nbsp;3&nbsp;dimensions,&nbsp;because...&nbsp;The&nbsp;4th&nbsp;dimension&nbsp;is&nbsp;determined&nbsp;by&nbsp;the&nbsp;packet&nbsp;size</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Reshape((-</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">4</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Convolutional&nbsp;layer&nbsp;with&nbsp;8&nbsp;filters</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Conv2D(</span><span class="f_CodeExample" style="color: #008100;">8</span><span class="f_CodeExample">,(</span><span class="f_CodeExample" style="color: #008100;">3</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">),</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">,activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Pooling&nbsp;layer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.MaxPooling2D((</span><span class="f_CodeExample" style="color: #008100;">2</span><span class="f_CodeExample">,</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">),strides=</span><span class="f_CodeExample" style="color: #008100;">1</span><span class="f_CodeExample">),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">#&nbsp;Reformat&nbsp;the&nbsp;tensor&nbsp;into&nbsp;a&nbsp;two-dimensional&nbsp;one&nbsp;for&nbsp;fully&nbsp;connected&nbsp;layers</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Flatten(),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(</span><span class="f_CodeExample" style="color: #008100;">40</span><span class="f_CodeExample">,&nbsp;activation=tf.nn.swish,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_regularizer=keras.regularizers.l1_l2(l1=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-7</span><span class="f_CodeExample">,&nbsp;l2=</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1e-5</span><span class="f_CodeExample">)),&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keras.layers.Dense(targerts,&nbsp;activation=tf.nn.tanh)&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;])</span></p>
</td>
</tr>
</table>
</div>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:665px"><img class="help" alt="Neural network structure with a two-dimensional convolutional layer" title="Neural network structure with a two-dimensional convolutional layer" width="665" height="525" style="width:665px;height:525px;border:none" src="conv2d_summary.png"/><p style="text-align:center"><span class="f_ImageCaption">Neural network structure with a two-dimensional convolutional layer</span></p></div></div>
<p class="p_Text"><span class="f_Text">The rest of our script will remain unchanged. We will learn more about the script results in the next section.</span></p>

</div>

</body>
</html>
