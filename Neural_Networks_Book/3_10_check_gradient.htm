<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <title>3.10 Gradient distribution verification</title>
  <meta name="keywords" content="" />
  <link type="text/css" href="default.css" rel="stylesheet" />

   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>


</head>

<body style="background-color:#FFFFFF; font-family:'Trebuchet MS',Tahoma,Arial,Helvetica,sans-serif; margin:0px;">



<table width="100%" height="49"  border="0" cellpadding="0" cellspacing="0" style="margin-top:0px; background-color:#1660af;">
  <tr>
    <td></td>
    <td valign="middle">
      <table style="margin-top:4px; margin-bottom:5px;" width="100%"  border="0" cellspacing="0" cellpadding="5">
        <tr valign="middle">
          <td class="nav">
<a class="h_m" href="index.htm">          Neural Networks for Algorithmic Trading with MQL5 </a> / <a class="h_m" href="3_realization.htm"> 3. Building the first neural network model in MQL5 </a>/ 3.10 Gradient distribution verification
          </td>
          <td width="70" align="right">
          <a href="3_9_create_data.htm"><img style="vertical-align:middle;" src="previous.png" alt="?????" width="27" height="27" border=0></a>&nbsp;
          <a href="3_11_realizations_comparison.htm"><img style="vertical-align:middle;" src="next.png" alt="??????" width="27" height="27" border="0"></a>
          </td>
        </tr>
      </table>
    </td>
    <td width="5"></td>
  </tr>
</table>



<div id="help">
<p class="p_H2"><span class="f_H2">3.10 Gradient distribution verification</span></p>
<p class="p_Text"><span class="f_Text">Now is the moment when we will assemble the first neural network using MQL5. However, I won't raise your hopes too much as our first neural network will not analyze or predict anything. Instead, it will perform a control function and verify the correctness of the work done earlier. The reason is that before we proceed directly to training the neural network, we need to check the correctness of the error gradient distribution throughout the neural network. I believe it is clear that the correctness of implementing this process significantly affects the overall result of the neural network training. After all, it is the error gradient on each weight that determines the magnitude and direction of its change.</span></p>
<p class="p_Text"><span class="f_Text">To verify the correctness of gradient distribution, we can use the fact that there are two options to determine the derivative of a function:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">Analytical</span><span class="f_li">: determining the gradient of a function based on its first-order derivative. This method is implemented in our backward pass method.</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">Empirical</span><span class="f_li">: under other equal conditions, the value of one indicator is changed and its effect on the final result of the function is evaluated.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">In its geometric interpretation, the gradient is the slope of the tangent to the graph of the function at the current point. It indicates how the value of the function changes with a change in the parameter value.</span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:600px"><img class="help" id="FIGFF4AD571" alt="The geometric meaning of the gradient is the slope of the tangent to the graph of the function at the current point" title="The geometric meaning of the gradient is the slope of the tangent to the graph of the function at the current point" width="600" height="300" style="width:600px;height:300px;border:none" src="gradient.png"/><p style="text-align:center"><span class="f_ImageCaption">In geometry terms, the gradient is the slope of the tangent to the graph of the function at the current point</span></p></div></div>
<p class="p_Text"><span class="f_Text">To draw a line, we need two points. Therefore, in two simple iterations, we can find these points on the graph of the function. First, we need to add a small number to the current value of the parameter and calculate the value of the function without changing the other parameters. This will be the first point. We repeat the iteration, but this time we subtract the same number from the current value and get the second point. The line passing through these two points will approximate the desired tangent with a certain degree of error. The smaller the number used to change the parameter, the smaller this error will be. This is the basis of the </span><span class="f_Text" style="font-style: italic;">empirical</span><span class="f_Text"> method for determining the gradient.</span></p>
<p class="p_Text"><span class="f_Text">If this method is so simple, why not use it consistently? Everything is quite simple here. The method simplicity hides a large number of operations:</span></p>
<ol style="list-style-type:decimal">
<li value="1" class="p_li"><span class="f_li">Perform a forward pass and save its result.</span></li>
<li value="2" class="p_li"><span class="f_li">Slightly increase one parameter and repeat the forward pass with the result saved.</span></li>
<li value="3" class="p_li"><span class="f_li">Slightly decrease one parameter and repeat the forward pass with the result saved.</span></li>
<li value="4" class="p_li"><span class="f_li">Based on the found points, construct a line and determine its slope.</span></li>
</ol>
<p class="p_Text"><span class="f_Text">All these steps are performed to determine the gradient at only one step for one parameter. Imagine how much time and computational resources we would need if we used this method in training a neural network with even just a hundred parameters. Do not forget that modern neural networks contain significantly more parameters. For instance, a giant model like GPT-3 contains 175 billion parameters. Of course, we will not build such giants on a home computer. However, the use of the analytical method greatly reduces the number of necessary iterations and the time for their execution.</span></p>
<p class="p_Text"><span class="f_Text">At the same time, we can build a small neural network and compare the results of the two methods on it. Their similarity will indicate the correctness of the implemented analytical method algorithm. Significant discrepancies in the results of the two methods will indicate the need to reevaluate the backward pass algorithm implemented in the analytical method.</span></p>
<p class="p_Text"><span class="f_Text">To implement this idea in practice, let's create the script </span><span class="f_Text" style="font-style: italic;">check_gradient_percp.mq5</span><span class="f_Text">. This script will receive three external parameters:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li">the size of the initial data vector,</span></li>
<li class="p_li"><span class="f_li">flag for using OpenCL technology,</span></li>
<li class="p_li"><span class="f_li">function to activate the hidden layer.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">Please note that we haven't specified the source of the original data. The reason is that for this work, it doesn't matter at all what data will be input into the model. We only check the correctness of the backward pass methods. Therefore, we can use a vector of random values as initial data.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//+------------------------------------------------------------------+</span>
<br><span class="f_CodeExample" style="color: #808080;">//|&nbsp;External&nbsp;parameters&nbsp;for&nbsp;the&nbsp;script&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</span>
<br><span class="f_CodeExample" style="color: #808080;">//+------------------------------------------------------------------+</span>
<br><span class="f_CodeExample" style="color: #808080;">//&nbsp;Source&nbsp;data&nbsp;vector&nbsp;size</span>
<br><span class="f_CodeExample" style="color: #0000ff;">input</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;</span><span class="f_CodeExample">40</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample" style="color: #808080;">//&nbsp;Use&nbsp;OpenCL</span>
<br><span class="f_CodeExample" style="color: #0000ff;">input</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">UseOpenCL</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample" style="color: #808080;">//&nbsp;Hidden&nbsp;Layer&nbsp;Activation&nbsp;Function</span>
<br><span class="f_CodeExample" style="color: #0000ff;">input</span><span class="f_CodeExample">&nbsp;</span><span class="f_Definition">ENUM_ACTIVATION_FUNCTION</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">HiddenActivation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Functions">AF_SWISH</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">In addition, in the global scope of the script, we will connect our library and declare a neural network object.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//+------------------------------------------------------------------+</span>
<br><span class="f_CodeExample" style="color: #808080;">//|&nbsp;Connecting&nbsp;the&nbsp;Neural&nbsp;Network&nbsp;Library&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|</span>
<br><span class="f_CodeExample" style="color: #808080;">//+------------------------------------------------------------------+</span>
<br><span class="f_CodeExample" style="color: #0000ff;">#include</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #008080;">&quot;..\..\..\Include\NeuroNetworksBook\realization\neuronnet.mqh&quot;</span>
<br><span class="f_CodeExample" style="color: #333333;">CNet</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">At the beginning of the script body, let's define the architecture of a small neural network. However, since we will need to perform similar tasks multiple times to validate the correctness of the process in different architectural solutions, we will encapsulate the model creation in a separate procedure called </span><span class="f_Text" style="font-style: italic;">CreateNet</span><span class="f_Text">. In the parameters, this procedure receives a pointer to the object of the neural network model being created.</span></p>
<p class="p_Text"><span class="f_Text">Let me remind you that earlier we created the </span><span class="f_Text" style="font-style: italic;"><a href="3_4_3_neuron_base.htm#cnetcreate" class="topiclink">CNet::Create</a></span><span class="f_Text"> method to create a neural network model. In parameters, this method takes a dynamic array of descriptions of the neural network architecture. Therefore, we need to organize a similar description of the new model. Let's collect the description of each neural layer into a separate instance of the </span><span class="f_Text" style="font-style: italic;"><a href="3_4_2_description.htm" class="topiclink">CLayerDescription</a></span><span class="f_Text"> class. We will combine them into a dynamic array </span><span class="f_Text" style="font-style: italic;">CArrayObj</span><span class="f_Text">. When adding neuron descriptions to a dynamic array, make sure that their sequence strictly corresponds to the arrangement of neural layers in the neural network. In my practice, I simply create layer descriptions sequentially in the order of their arrangement in the neural network and add them to the array as I create them.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CreateNet</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNet</span><span class="f_CodeExample">&nbsp;&amp;</span><span class="f_CodeExample" style="color: #333333;">net</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CArrayObj</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CArrayObj</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;CArrayObj:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">To check the correctness of the implemented error propagation algorithm, we will create a three-layer neural network. All layers will be built on the basis of the </span><span class="f_Text" style="font-style: italic;"><a href="3_6_2_pr_mql5.htm" class="topiclink">CNeuronBase</a></span><span class="f_Text"> class we created. The size of the first neural layer of the initial data was specified by the user in the external parameter </span><span class="f_Text" style="font-style: italic;">BarsToLine</span><span class="f_Text">. We will create it without an activation function and weight update method. In theory, this is the basic approach to creating a source data layer.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;source&nbsp;data&nbsp;layer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;CLayerDescription:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">defNeuronBase</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">AF_NONE</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">optimization</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">None</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Add</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;adding&nbsp;layer:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">We will set the number of neurons in the second (hidden) neural layer to be 10 times greater than the input data layer. However, the actual size of the neural layer does not directly affect the process of analyzing the algorithm performance. This layer will already receive the activation function that the user specifies in the external parameter of the </span><span class="f_Text" style="font-style: italic;">HiddenActivation</span><span class="f_Text"> script. For example, I used Swish. I would recommend experimenting with all the activation functions you're using. At this stage, we want to verify the correctness of all the methods we've written so far. Exactly, the more diverse your testing is, the more potential issues you can address at this stage. This will help you avoid distractions during the actual training of the neural network and focus on improving its performance.</span></p>
<p class="p_Text"><span class="f_Text">At this stage, we will not perform weight updates. Therefore, the specified method of updating the weights will not affect our testing results in any way.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;hidden&nbsp;layer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;CLayerDescription:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">defNeuronBase</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">10</span><span class="f_CodeExample">&nbsp;*&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">HiddenActivation</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">optimization</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">Adam</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">]&nbsp;=&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_CodeExample">1</span><span class="f_CodeExample">]&nbsp;=&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Add</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;adding&nbsp;layer:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The third neural layer will contain only one output neuron and a linear activation function.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;result&nbsp;layer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;CLayerDescription:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">defNeuronBase</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">AF_LINEAR</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">optimization</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">Adam</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_CodeExample">1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_CodeExample">1</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Add</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;adding&nbsp;layer:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">descr</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Having collected a complete description of the neural network in a single dynamic array, we generate a neural network. To do this, we call the </span><span class="f_Text" style="font-style: italic;">CNet::Create</span><span class="f_Text"> method of our base neural network class, in which the neural network is generated according to the passed description. At each step, we check the correctness of performing operations on the returned results. Receiving the boolean value </span><span class="f_Text" style="font-style: italic;">true</span><span class="f_Text"> corresponds to the correct execution of the method's operations. If any of the errors occur, the method will return </span><span class="f_Text" style="font-style: italic;">false</span><span class="f_Text">.</span></p>
<p class="p_Text"><span class="f_Text">We will specify the flag for using OpenCL. For full testing, we have to check the correctness of the backpropagation method in both modes of operation of the neural network.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;the&nbsp;neural&nbsp;network</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Create</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">,&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">3.0e-4</span><span class="f_CodeExample">,&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">0.9</span><span class="f_CodeExample">,&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">0.999</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">LOSS_MAE</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;of&nbsp;init&nbsp;Net:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">layers</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">UseOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #b22222;">UseOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Use&nbsp;OpenCL&nbsp;%s&quot;</span><span class="f_CodeExample">,&nbsp;(</span><span class="f_CodeExample" style="color: #0000ff;">string</span><span class="f_CodeExample">)</span><span class="f_CodeExample" style="color: #333333;">net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">UseOpenCL</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">We conclude or work with the model creation procedure and move on to the main procedure of our </span><span class="f_Text" style="font-style: italic;">OnStart</span><span class="f_Text"> script. In it, to create a neural network model, we just need to call the above procedure.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">&nbsp;</span><span class="f_Functions">OnStart</span><span class="f_CodeExample">()</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #808080;">//---&nbsp;create&nbsp;a&nbsp;model</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">CreateNet</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">At this stage, the neural network object is ready for testing. However, we still need initial data for testing. As mentioned above, we will simply populate them with random values. We will create the </span><span class="f_Text" style="font-style: italic;"><a href="3_7_2_opencl_transfer_data.htm#cbuffertype" class="topiclink">CBufferType</a></span><span class="f_Text"> data buffer to store a sequence of initial data. Target results are not of interest at this point. When generating the neural network, we filled the weight matrix with random values and do not expect to hit the target values. We also do not plan to train the neural network at this stage. Therefore, we will not waste resources on downloading unnecessary information.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;create&nbsp;a&nbsp;buffer&nbsp;to&nbsp;read&nbsp;the&nbsp;source&nbsp;data</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;Pattern&nbsp;data&nbsp;array:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">In the loop, fill the entire buffer with random values.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;generate&nbsp;random&nbsp;source&nbsp;data</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferInit</span><span class="f_CodeExample">(</span><span class="f_CodeExample">1</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">for</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">i</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">i</span><span class="f_CodeExample">&nbsp;&lt;&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">i</span><span class="f_CodeExample">++)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">i</span><span class="f_CodeExample">]&nbsp;=&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_Functions">MathRand</span><span class="f_CodeExample">()&nbsp;/&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">32767</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Now there is enough information to conduct a forward pass of the neural network. We will implement it by calling the </span><span class="f_Text" style="font-style: italic;"><a href="3_4_3_neuron_base.htm#feedforward" class="topiclink">FeedForward</a></span><span class="f_Text"> method of our neural network. The results of the direct pass will be stored in a separate data buffer of reference values. Probably the name </span><span class="f_Text" style="font-style: italic;">reference</span><span class="f_Text"> for a randomly obtained result sounds strange. But within the scope of our testing, this will be the reference against which we will consider deviations when changing the input data or weights.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;perform&nbsp;a&nbsp;forward&nbsp;and&nbsp;reverse&nbsp;pass&nbsp;to&nbsp;obtain&nbsp;analytical&nbsp;gradients</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">&nbsp;=&nbsp;(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)</span><span class="f_CodeExample">1.0e-5</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Copy</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;FeedForward:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetResults</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;GetResult:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">In the next step, we add a small constant to the result of the feed-forward pass and run the backpropagation pass of our neural network to calculate the error gradients analytically. In the above example, I used the constant </span><span class="f_Text" style="font-style: italic;">1*10</span><span class="f_Text" style="font-size: 7pt; font-style: italic; vertical-align: super;">-5</span><span class="f_Text" style="font-style: italic;"> </span><span class="f_Text">as a deviation.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;create&nbsp;a&nbsp;result&nbsp;buffer</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;Pattern&nbsp;Target&nbsp;array:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample" style="color: #808080;">//---&nbsp;save&nbsp;obtained&nbsp;data&nbsp;to&nbsp;separate&nbsp;buffers</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Copy</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">]&nbsp;+&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Backpropagation</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;Backpropagation:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">input_gradient</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetGradient</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">0</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">1</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">weights_gradient</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetDeltaWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">1</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #b22222;">UseOpenCL</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">input_gradient</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferRead</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferRead</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights_gradient</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferRead</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Please note that we need to keep the reference result unchanged. That's why we needed to create another data buffer object, into which we copied values from the benchmark values buffer. In this buffer, we correct the data for the backpropagation pass.</span></p>
<p class="p_Text"><span class="f_Text">According to the results of the backpropagation pass, we will save the error gradients obtained analytically at the level of the initial data and weights. We also save the weights themselves, which we will need when analyzing the distribution of error gradients at the level of the weight matrix.</span></p>
<p class="p_Text"><span class="f_Text">Perhaps it's worth mentioning that since we adjust the weights during the training process, obtaining accurate gradients at the weight matrix level is most informative for us. Accurate gradients at the level of input data mostly serve as indirect evidence of the correctness of gradient distribution throughout the entire neural network. This is due to the fact that before determining the error gradient at the level of the initial data, we have to consistently draw it analytically through all layers of our neural network.</span></p>
<p class="p_Text"><span class="f_Text">We obtained the error gradients by an analytical method. Next, we need to determine the gradients empirically and compare them with the results of the analytical method.</span></p>
<p class="p_Text"><span class="f_Text">Let's look at the initial data level first. To achieve this, we will copy our pattern of input data into a new dynamic array, which will allow us to modify the required indicators without the fear of losing the original pattern.</span></p>
<p class="p_Text"><span class="f_Text">We will organize a loop to enumerate all the indicators of our pattern. Inside the loop, we will first add our constant </span><span class="f_Text" style="font-style: italic;">1*10</span><span class="f_Text" style="font-size: 7pt; font-style: italic; vertical-align: super;">-5</span><span class="f_Text"> to each indicator of the original pattern in turn and implement a feed-forward pass neural network. After the feed-forward pass, we take the result obtained and compare it with the reference one that was saved earlier. The difference between the results of the feed-forward pass will be stored in a separate variable. Then we subtract a constant from the initial value of the same indicator and repeat the feed-forward pass. The result of the feed-forward pass is also comparable to the reference result. Let's find the arithmetic mean of two passes.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;in&nbsp;the&nbsp;loop,&nbsp;alternately&nbsp;change&nbsp;the&nbsp;elements&nbsp;of&nbsp;the&nbsp;source&nbsp;data&nbsp;and&nbsp;compare</span>
<br><span class="f_CodeExample" style="color: #808080;">//---&nbsp;empirical&nbsp;result&nbsp;with&nbsp;the&nbsp;value&nbsp;of&nbsp;the&nbsp;analytical&nbsp;method</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">for</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;&lt;&nbsp;</span><span class="f_CodeExample" style="color: #b22222;">BarsToLine</span><span class="f_CodeExample">;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">++)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Copy</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">]&nbsp;+&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;FeedForward:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetResults</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;GetResult:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">);</span></p>
</td>
</tr>
</table>
</div>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">[</span><span class="f_CodeExample">0</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">]&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;FeedForward:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetResults</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;GetResult:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;-=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;/=&nbsp;</span><span class="f_CodeExample">2</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;+=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">input_gradient</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">pattern</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">At this point, you should be careful with the signs of the operation and deviations. In the first case, we added a constant and obtained some deviation in the results. The deviation is considered as the current value minus the reference.</span></p>
<p class="p_Text" style="text-align: center;"><span style="display:inline-block;width:207px;height:22px;padding:0 0;overflow:visible"><svg xmlns="http://www.w3.org/2000/svg" style="width:100%;height:100%;overflow:visible" viewBox="0 0 828 88"><path d="M2 51 L2 49 L21 0 L27 0 L42 49 L42 51 L2 51 Z M8 45 L34 45 L22 8 L8 45 Z" fill="#212121"/><path d="M71 25 L71 20 L117 20 L117 25 L71 25 Z M71 40 L71 35 L117 35 L117 40 L71 40 Z" fill="#212121"/><path d="M173 28 C174 29,175 30,176 31 C177 32,177 34,178 36 L179 41 C179 42,179 43,180 44 C180 45,180 46,181 47 C181 48,182 48,182 49 C183 49,184 49,185 49 L185 51 L174 51 C174 49,173 46,172 43 L171 35 C171 34,170 33,170 32 C169 31,169 30,168 29 C168 29,167 29,167 28 C166 28,165 28,164 28 L160 28 L157 40 C157 41,157 42,157 42 C157 43,157 44,157 44 C157 45,157 45,157 46 C157 47,157 47,157 48 C157 48,158 48,158 49 C159 49,159 49,161 49 L160 51 L145 51 L145 49 C146 49,147 49,148 48 C148 48,148 48,149 47 C149 46,149 46,150 45 C150 44,150 42,151 40 L157 12 C158 10,158 8,158 6 C158 5,158 4,157 4 C157 3,156 3,154 3 L155 1 L171 1 C174 1,176 1,177 2 C179 2,180 2,182 3 C183 4,184 4,184 5 C185 6,186 7,186 8 C187 10,187 11,187 12 C187 16,186 19,183 21 C181 24,178 26,173 27 L173 28 Z M165 25 C168 25,171 25,173 24 C175 23,177 21,178 19 C179 17,180 15,180 12 C180 11,180 10,180 9 C179 9,179 8,179 7 C179 7,178 6,178 6 C177 6,177 5,176 5 C175 5,174 4,173 4 C172 4,171 4,169 4 C168 4,167 4,165 4 L161 25 L165 25 Z" fill="#212121"/><path d="M219 48 L216 48 C216 47,216 46,216 45 C215 45,215 44,215 44 C214 43,214 43,213 42 C212 42,212 42,211 42 C209 42,208 42,207 43 C206 44,205 45,204 46 C203 47,202 48,201 50 C200 51,200 53,199 54 C198 56,198 58,198 59 C197 61,197 63,197 64 C197 67,198 69,199 70 C200 72,201 72,203 72 C205 72,205 72,206 72 C207 72,208 71,209 71 C210 70,210 70,211 69 C211 68,212 67,213 66 L216 66 L214 73 C213 74,212 74,211 74 C210 74,209 75,208 75 C208 75,207 75,206 75 C205 75,204 75,203 75 C201 75,200 75,198 74 C197 74,196 73,195 72 C194 71,193 70,192 68 C192 67,192 65,192 63 C192 61,192 59,192 57 C193 55,194 53,194 51 C195 49,196 47,198 46 C199 45,200 43,201 42 C203 41,204 41,206 40 C208 39,209 39,211 39 C212 39,213 39,213 39 C214 39,215 39,216 39 C216 40,217 40,218 40 C219 40,220 40,221 41 L219 48 Z" fill="#212121"/><path d="M243 67 C241 70,239 71,238 72 C236 74,234 74,232 74 C231 74,229 74,228 73 C227 72,227 70,227 69 C227 68,227 68,227 67 C227 66,227 65,228 64 C228 63,228 62,228 61 C229 60,229 59,229 58 C229 57,230 56,230 55 C230 54,230 53,230 53 C230 52,230 51,229 51 C228 51,228 51,228 51 C227 51,227 52,226 52 C226 52,226 53,225 53 C225 53,224 54,224 54 L222 53 C223 52,224 51,225 50 C225 49,226 49,227 48 C227 48,228 48,229 47 C229 47,230 47,231 47 C232 47,233 48,234 48 C235 49,235 50,235 52 C235 52,235 53,235 54 C235 55,235 56,234 57 C234 59,233 62,233 63 C232 65,232 66,232 67 C232 68,232 69,233 69 C233 70,234 70,235 70 C236 70,236 70,237 69 C238 69,239 68,240 67 C241 66,242 65,243 64 C243 62,244 61,244 60 L247 47 L252 47 L248 64 C248 65,248 66,248 66 C248 67,248 68,248 68 C248 69,248 69,248 70 C248 70,249 70,249 70 C249 70,250 70,250 70 C250 70,251 70,251 69 C252 69,252 69,252 68 C253 68,253 67,254 67 L256 68 C255 70,254 70,253 71 C252 72,252 72,251 73 C250 73,250 74,249 74 C248 74,248 74,247 74 C246 74,245 74,244 73 C243 72,243 71,243 70 C243 69,243 69,243 68 C243 68,243 68,243 67 L243 67 Z" fill="#212121"/><path d="M266 57 C266 56,266 55,266 55 C266 54,266 53,266 53 C266 52,266 51,265 51 C264 51,264 51,264 51 C263 51,263 52,263 52 C262 52,262 53,261 53 C261 53,261 54,260 54 L258 53 C259 52,260 51,261 50 C261 49,262 49,263 48 C263 48,264 48,265 47 C265 47,266 47,267 47 C268 47,269 48,270 48 C271 49,271 50,271 52 C271 53,271 53,271 54 L271 54 C273 52,275 50,276 49 C278 48,280 47,282 47 C282 47,283 47,283 47 C284 47,285 47,285 47 L284 54 L281 54 C281 53,280 52,280 52 C280 51,279 51,278 51 C278 51,278 51,277 51 C276 52,276 52,275 53 C275 53,274 54,273 54 C273 55,272 56,272 57 C271 57,271 58,270 59 C270 60,270 61,270 62 L267 74 L262 74 L266 57 Z" fill="#212121"/><path d="M295 57 C295 56,295 55,295 55 C295 54,295 53,295 53 C295 52,295 51,294 51 C293 51,293 51,293 51 C292 51,292 52,292 52 C291 52,291 53,290 53 C290 53,290 54,289 54 L287 53 C288 52,289 51,290 50 C290 49,291 49,292 48 C292 48,293 48,294 47 C294 47,295 47,296 47 C297 47,298 48,299 48 C300 49,300 50,300 52 C300 53,300 53,300 54 L300 54 C302 52,304 50,305 49 C307 48,309 47,311 47 C311 47,312 47,312 47 C313 47,314 47,314 47 L313 54 L310 54 C310 53,309 52,309 52 C309 51,308 51,307 51 C307 51,307 51,306 51 C305 52,305 52,304 53 C304 53,303 54,302 54 C302 55,301 56,301 57 C300 57,300 58,299 59 C299 60,299 61,299 62 L296 74 L291 74 L295 57 Z" fill="#212121"/><path d="M340 68 C338 70,336 72,334 73 C332 74,330 74,327 74 C326 74,325 74,323 73 C322 73,321 73,321 72 C320 71,319 70,319 69 C319 68,318 67,318 65 C318 64,319 63,319 62 C319 61,319 60,320 59 C320 58,320 57,321 56 C322 55,322 54,323 53 C324 51,326 50,328 49 C330 48,333 47,335 47 C338 47,339 48,341 49 C342 50,342 51,342 53 C342 59,336 62,324 62 C324 63,324 63,324 64 C324 64,324 65,324 65 C324 67,324 69,325 70 C326 71,327 71,329 71 C329 71,330 71,331 71 C332 71,333 70,333 70 C334 70,335 69,336 68 C336 68,337 67,338 66 L340 68 Z M324 59 C327 59,329 59,330 59 C332 58,333 58,334 57 C335 57,336 56,337 56 C337 55,337 54,337 53 C337 52,337 52,337 51 C336 50,335 50,334 50 C333 50,332 50,331 51 C330 51,329 52,329 53 C328 53,327 54,326 55 C326 56,325 58,324 59 L324 59 Z" fill="#212121"/><path d="M359 54 C361 52,362 50,364 49 C366 48,368 47,369 47 C371 47,373 48,374 49 C375 50,375 51,375 53 C375 53,375 54,375 55 C375 56,374 57,374 58 C374 59,374 60,373 61 C373 62,373 64,372 64 C372 65,372 66,372 67 C372 68,372 68,372 68 C372 69,372 69,372 70 C372 70,373 70,373 70 C374 70,374 70,374 70 C375 70,375 70,375 69 C376 69,376 69,376 68 C377 68,377 67,378 67 L380 68 C379 70,378 70,377 71 C377 72,376 72,375 73 C375 73,374 74,373 74 C372 74,372 74,371 74 C370 74,370 74,369 74 C369 74,368 73,368 73 C367 72,367 72,367 71 C367 71,367 70,367 69 C367 69,367 68,367 67 C367 66,367 65,367 64 C368 63,368 62,368 61 C369 60,369 59,369 58 C369 57,369 57,370 56 C370 55,370 55,370 54 C370 53,370 52,369 52 C369 51,368 51,367 51 C367 51,366 51,365 51 C365 52,364 52,363 53 C363 53,362 54,362 54 C361 55,360 56,360 56 C359 57,359 58,359 59 C358 60,358 60,358 61 L355 74 L350 74 L354 57 C354 56,354 56,354 55 C354 54,354 53,354 53 C354 52,354 51,353 51 C352 51,352 51,352 51 C351 51,351 52,351 52 C350 52,350 53,349 53 C349 53,349 54,348 54 L346 53 C347 52,348 51,349 50 C349 49,350 49,351 48 C351 48,352 48,353 47 C353 47,354 47,355 47 C356 47,357 48,358 48 C359 49,359 50,359 52 C359 52,359 53,359 53 C359 53,359 54,359 54 L359 54 Z" fill="#212121"/><path d="M402 68 C401 69,400 70,399 71 C398 72,398 72,397 73 C396 73,395 74,394 74 C394 74,393 74,392 74 C390 74,388 74,387 73 C386 72,386 70,386 68 C386 68,386 67,386 66 C386 65,386 65,386 64 L389 50 L385 50 L385 48 C386 48,387 48,388 48 C389 48,389 47,389 47 C390 47,390 46,390 46 C390 46,391 45,391 45 C391 44,391 43,392 43 C392 42,392 41,393 40 L397 40 L395 47 L404 47 L404 50 L395 50 L392 61 C392 62,392 62,391 63 C391 64,391 64,391 64 C391 65,391 65,391 66 C391 66,391 66,391 67 C391 68,391 69,392 69 C392 70,393 70,394 70 C395 70,396 70,397 69 C398 69,399 68,400 66 L402 68 Z" fill="#212121"/><path d="M430 32 L430 27 L476 27 L476 32 L430 32 Z" fill="#212121"/><path d="M528 28 C529 29,530 30,531 31 C532 32,532 34,533 36 L534 41 C534 42,534 43,535 44 C535 45,535 46,536 47 C536 48,537 48,537 49 C538 49,539 49,540 49 L540 51 L529 51 C529 49,528 46,527 43 L526 35 C526 34,525 33,525 32 C524 31,524 30,523 29 C523 29,522 29,522 28 C521 28,520 28,519 28 L515 28 L512 40 C512 41,512 42,512 42 C512 43,512 44,512 44 C512 45,512 45,512 46 C512 47,512 47,512 48 C512 48,513 48,513 49 C514 49,514 49,516 49 L515 51 L500 51 L500 49 C501 49,502 49,503 48 C503 48,503 48,504 47 C504 46,504 46,505 45 C505 44,505 42,506 40 L512 12 C513 10,513 8,513 6 C513 5,513 4,512 4 C512 3,511 3,509 3 L510 1 L526 1 C529 1,531 1,532 2 C534 2,535 2,537 3 C538 4,539 4,539 5 C540 6,541 7,541 8 C542 10,542 11,542 12 C542 16,541 19,538 21 C536 24,533 26,528 27 L528 28 Z M520 25 C523 25,526 25,528 24 C530 23,532 21,533 19 C534 17,535 15,535 12 C535 11,535 10,535 9 C534 9,534 8,534 7 C534 7,533 6,533 6 C532 6,532 5,531 5 C530 5,529 4,528 4 C527 4,526 4,524 4 C523 4,522 4,520 4 L516 25 L520 25 Z" fill="#212121"/><path d="M558 61 C558 62,557 63,557 64 C557 65,557 66,556 67 C556 68,556 69,556 70 C556 71,556 71,556 72 C556 72,556 73,556 73 C556 73,556 73,556 74 C556 74,557 74,557 74 C558 74,558 74,559 74 L558 76 L547 76 L547 74 C548 74,548 74,548 74 C549 74,549 73,549 73 C550 73,550 72,550 71 C550 71,551 69,551 68 L555 49 C556 48,556 47,556 47 C556 46,556 46,556 45 C556 45,556 44,555 44 C555 43,554 43,553 43 L553 41 L566 41 C568 41,570 41,572 42 C573 42,575 43,575 43 C576 44,577 45,577 46 C578 47,578 48,578 49 C578 52,577 54,576 56 C574 58,572 59,568 60 C568 60,568 60,568 60 C568 60,568 60,568 60 C569 61,570 62,570 63 C571 63,571 65,572 66 C572 68,572 69,573 70 C573 71,573 72,574 72 C574 73,574 73,575 73 C576 74,576 74,577 74 L577 76 L569 76 C569 75,568 75,568 74 C568 73,568 72,567 71 C567 69,567 68,566 67 C566 66,566 65,566 64 C565 64,565 63,565 63 C565 62,564 62,564 62 C564 62,563 61,563 61 C562 61,562 61,561 61 L558 61 Z M562 58 C565 58,568 57,570 56 C572 55,573 52,573 49 C573 48,573 48,572 47 C572 46,571 46,571 45 C570 45,569 45,568 44 C567 44,566 44,565 44 C564 44,564 44,563 44 C563 44,562 44,562 44 L558 58 L562 58 Z" fill="#212121"/><path d="M606 70 C604 72,602 74,600 75 C598 76,596 76,593 76 C592 76,591 76,589 75 C588 75,587 75,587 74 C586 73,585 72,585 71 C585 70,584 69,584 67 C584 66,585 65,585 64 C585 63,585 62,586 61 C586 60,586 59,587 58 C588 57,588 56,589 55 C590 53,592 52,594 51 C596 50,599 49,601 49 C604 49,605 50,607 51 C608 52,608 53,608 55 C608 61,602 64,590 64 C590 65,590 65,590 66 C590 66,590 67,590 67 C590 69,590 71,591 72 C592 73,593 73,595 73 C595 73,596 73,597 73 C598 73,599 72,599 72 C600 72,601 71,602 70 C602 70,603 69,604 68 L606 70 Z M590 61 C593 61,595 61,596 61 C598 60,599 60,600 59 C601 59,602 58,603 58 C603 57,603 56,603 55 C603 54,603 54,603 53 C602 52,601 52,600 52 C599 52,598 52,597 53 C596 53,595 54,595 55 C594 55,593 56,592 57 C592 58,591 60,590 61 L590 61 Z" fill="#212121"/><path d="M625 75 C624 79,623 82,621 84 C619 86,616 87,613 87 C612 87,612 87,611 87 C611 86,612 86,612 85 C612 85,612 85,612 84 C612 84,612 84,612 84 C613 84,613 84,613 84 C614 84,615 84,615 84 C616 84,616 83,617 83 C617 82,618 81,618 80 C619 79,619 78,619 76 L625 52 L620 52 L620 50 C621 50,622 50,623 50 C623 50,624 50,624 49 C625 49,625 49,625 48 C626 45,628 43,630 41 C632 40,635 39,638 39 C639 39,640 39,641 39 C641 39,642 39,643 40 L642 45 L639 45 C639 44,639 43,638 43 C638 42,637 42,636 42 C635 42,635 42,634 43 C633 43,633 44,632 44 C632 45,631 46,631 47 C631 48,630 48,630 49 L638 49 L637 52 L630 52 L625 75 Z" fill="#212121"/><path d="M669 70 C667 72,665 74,663 75 C661 76,659 76,656 76 C655 76,654 76,652 75 C651 75,650 75,650 74 C649 73,648 72,648 71 C648 70,647 69,647 67 C647 66,648 65,648 64 C648 63,648 62,649 61 C649 60,649 59,650 58 C651 57,651 56,652 55 C653 53,655 52,657 51 C659 50,662 49,664 49 C667 49,668 50,670 51 C671 52,671 53,671 55 C671 61,665 64,653 64 C653 65,653 65,653 66 C653 66,653 67,653 67 C653 69,653 71,654 72 C655 73,656 73,658 73 C658 73,659 73,660 73 C661 73,662 72,662 72 C663 72,664 71,665 70 C665 70,666 69,667 68 L669 70 Z M653 61 C656 61,658 61,659 61 C661 60,662 60,663 59 C664 59,665 58,666 58 C666 57,666 56,666 55 C666 54,666 54,666 53 C665 52,664 52,663 52 C662 52,661 52,660 53 C659 53,658 54,658 55 C657 55,656 56,655 57 C655 58,654 60,653 61 L653 61 Z" fill="#212121"/><path d="M683 59 C683 58,683 57,683 57 C683 56,683 55,683 55 C683 54,683 53,682 53 C681 53,681 53,681 53 C680 53,680 54,680 54 C679 54,679 55,678 55 C678 55,678 56,677 56 L675 55 C676 54,677 53,678 52 C678 51,679 51,680 50 C680 50,681 50,682 49 C682 49,683 49,684 49 C685 49,686 50,687 50 C688 51,688 52,688 54 C688 55,688 55,688 56 L688 56 C690 54,692 52,693 51 C695 50,697 49,699 49 C699 49,700 49,700 49 C701 49,702 49,702 49 L701 56 L698 56 C698 55,697 54,697 54 C697 53,696 53,695 53 C695 53,695 53,694 53 C693 54,693 54,692 55 C692 55,691 56,690 56 C690 57,689 58,689 59 C688 59,688 60,687 61 C687 62,687 63,687 64 L684 76 L679 76 L683 59 Z" fill="#212121"/><path d="M728 70 C726 72,724 74,722 75 C720 76,718 76,715 76 C714 76,713 76,711 75 C710 75,709 75,709 74 C708 73,707 72,707 71 C707 70,706 69,706 67 C706 66,707 65,707 64 C707 63,707 62,708 61 C708 60,708 59,709 58 C710 57,710 56,711 55 C712 53,714 52,716 51 C718 50,721 49,723 49 C726 49,727 50,729 51 C730 52,730 53,730 55 C730 61,724 64,712 64 C712 65,712 65,712 66 C712 66,712 67,712 67 C712 69,712 71,713 72 C714 73,715 73,717 73 C717 73,718 73,719 73 C720 73,721 72,721 72 C722 72,723 71,724 70 C724 70,725 69,726 68 L728 70 Z M712 61 C715 61,717 61,718 61 C720 60,721 60,722 59 C723 59,724 58,725 58 C725 57,725 56,725 55 C725 54,725 54,725 53 C724 52,723 52,722 52 C721 52,720 52,719 53 C718 53,717 54,717 55 C716 55,715 56,714 57 C714 58,713 60,712 61 L712 61 Z" fill="#212121"/><path d="M747 56 C749 54,750 52,752 51 C754 50,756 49,757 49 C759 49,761 50,762 51 C763 52,763 53,763 55 C763 55,763 56,763 57 C763 58,762 59,762 60 C762 61,762 62,761 63 C761 64,761 66,760 66 C760 67,760 68,760 69 C760 70,760 70,760 70 C760 71,760 71,760 72 C760 72,761 72,761 72 C762 72,762 72,762 72 C763 72,763 72,763 71 C764 71,764 71,764 70 C765 70,765 69,766 69 L768 70 C767 72,766 72,765 73 C765 74,764 74,763 75 C763 75,762 76,761 76 C760 76,760 76,759 76 C758 76,758 76,757 76 C757 76,756 75,756 75 C755 74,755 74,755 73 C755 73,755 72,755 71 C755 71,755 70,755 69 C755 68,755 67,755 66 C756 65,756 64,756 63 C757 62,757 61,757 60 C757 59,757 59,758 58 C758 57,758 57,758 56 C758 55,758 54,757 54 C757 53,756 53,755 53 C755 53,754 53,753 53 C753 54,752 54,751 55 C751 55,750 56,750 56 C749 57,748 58,748 58 C747 59,747 60,747 61 C746 62,746 62,746 63 L743 76 L738 76 L742 59 C742 58,742 58,742 57 C742 56,742 55,742 55 C742 54,742 53,741 53 C740 53,740 53,740 53 C739 53,739 54,739 54 C738 54,738 55,737 55 C737 55,737 56,736 56 L734 55 C735 54,736 53,737 52 C737 51,738 51,739 50 C739 50,740 50,741 49 C741 49,742 49,743 49 C744 49,745 50,746 50 C747 51,747 52,747 54 C747 54,747 55,747 55 C747 55,747 56,747 56 L747 56 Z" fill="#212121"/><path d="M791 57 C791 56,791 55,791 55 C791 54,791 54,791 53 C790 53,790 53,790 52 C789 52,789 52,788 52 C787 52,786 52,785 53 C784 53,784 54,783 54 C782 55,781 56,781 57 C780 58,780 59,779 60 C779 61,778 63,778 64 C778 65,778 66,778 67 C778 69,778 71,779 72 C780 73,781 73,782 73 C783 73,784 73,785 73 C785 73,786 72,787 72 C787 72,788 71,789 71 C789 70,790 69,791 68 C791 69,792 69,792 70 C792 70,793 70,793 71 C791 72,789 74,787 75 C785 76,783 76,781 76 C778 76,776 75,775 74 C773 72,772 70,772 67 C772 65,773 64,773 62 C773 61,774 59,775 58 C775 57,776 56,777 54 C778 53,779 52,780 52 C782 51,783 50,784 50 C786 49,787 49,789 49 C790 49,791 49,793 49 C794 49,795 50,796 50 L794 57 L791 57 Z" fill="#212121"/><path d="M822 70 C820 72,818 74,816 75 C814 76,812 76,809 76 C808 76,807 76,805 75 C804 75,803 75,803 74 C802 73,801 72,801 71 C801 70,800 69,800 67 C800 66,801 65,801 64 C801 63,801 62,802 61 C802 60,802 59,803 58 C804 57,804 56,805 55 C806 53,808 52,810 51 C812 50,815 49,817 49 C820 49,821 50,823 51 C824 52,824 53,824 55 C824 61,818 64,806 64 C806 65,806 65,806 66 C806 66,806 67,806 67 C806 69,806 71,807 72 C808 73,809 73,811 73 C811 73,812 73,813 73 C814 73,815 72,815 72 C816 72,817 71,818 70 C818 70,819 69,820 68 L822 70 Z M806 61 C809 61,811 61,812 61 C814 60,815 60,816 59 C817 59,818 58,819 58 C819 57,819 56,819 55 C819 54,819 54,819 53 C818 52,817 52,816 52 C815 52,814 52,813 53 C812 53,811 54,811 55 C810 55,809 56,808 57 C808 58,807 60,806 61 L806 61 Z" fill="#212121"/></svg></span></p>
<p class="p_Text"><span class="f_Text">In the second case, we subtracted the constant from the original value. Similarly, using the same formula for calculating the deviation, we will obtain a value with the opposite sign. Therefore, to combine the obtained results in magnitude and preserve the correct direction of the gradient, we need to subtract the second deviation from the first one.</span></p>
<p class="p_Text"><span class="f_Text">The result is divided by 2 to get the mean deviation. The result obtained is comparable to the result of the analytical method.</span></p>
<p class="p_Text"><span class="f_Text">We repeat the operations described above for all parameters of the initial pattern.</span></p>
<p class="p_Text"><span class="f_Text">There is another aspect that we should take into account. The gradient indicates how the function value changes when the parameter changes by 1. Our constant is much smaller. Therefore, the empirically calculated gradient we obtained is significantly underestimated. To compensate for this, let's divide the empirically obtained value by our constant and display the total result in the MetaTrader 5 log.</span></p>
<div style="text-align: justify; text-indent: 0; padding: 0 0 0 0; margin: 7px 17px 6px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;display&nbsp;the&nbsp;total&nbsp;value&nbsp;of&nbsp;deviations&nbsp;at&nbsp;the&nbsp;level&nbsp;of&nbsp;the&nbsp;initial&nbsp;data&nbsp;in&nbsp;the&nbsp;journal</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Delta&nbsp;at&nbsp;input&nbsp;gradient&nbsp;between&nbsp;methods&nbsp;%.5e&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;/&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">);</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Similarly, we determine the empirical gradient at the level of the weight matrix. Note that to access the matrix of weights, we obtain not a copy of the matrix but a pointer to the object. This is a very important point. Thanks to this, we can modify the values of weights directly in our script without creating additional methods to update buffer values in the neural network and neural layer classes. However, this approach is more of an exception than a general practice. The reason is that with this approach, we cannot track changes to the weight matrix from the neural layer object.</span></p>
<p class="p_Text"><span class="f_Text">The cumulative result of comparing empirical and analytical gradients at the weight matrix level is also printed to the MetaTrader 5 log.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;reset&nbsp;the&nbsp;value&nbsp;of&nbsp;the&nbsp;sum&nbsp;and&nbsp;repeat&nbsp;the&nbsp;loop&nbsp;for&nbsp;the&nbsp;gradients&nbsp;of&nbsp;the&nbsp;weights</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;creating&nbsp;reference&nbsp;weights&nbsp;buffer:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Copy</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">m_mMatrix</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;copying&nbsp;weights&nbsp;to&nbsp;initial&nbsp;weights&nbsp;buffer:&nbsp;%d&quot;</span><span class="f_CodeExample">,</span><br>
<span class="f_Functions">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">for</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">uint</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;&lt;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Total</span><span class="f_CodeExample">();&nbsp;</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">++)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;&gt;&nbsp;</span><span class="f_CodeExample">0</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Update</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">1</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">&nbsp;-&nbsp;</span><span class="f_CodeExample">1</span><span class="f_CodeExample">));</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Update</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">)&nbsp;+&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #b22222;">UseOpenCL</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferWrite</span><span class="f_CodeExample">())</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;FeedForward:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetResults</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;GetResult:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">);</span></p>
</td>
</tr>
</table>
</div>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Update</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #b22222;">UseOpenCL</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">weights</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferWrite</span><span class="f_CodeExample">())</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;FeedForward:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">Net</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetResults</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Error&nbsp;in&nbsp;GetResult:&nbsp;%d&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Functions">GetLastError</span><span class="f_CodeExample">());</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;-=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample">0</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">&nbsp;/=&nbsp;</span><span class="f_CodeExample">2</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;+=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">weights_gradient</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">At</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">k</span><span class="f_CodeExample">)&nbsp;-&nbsp;</span><span class="f_CodeExample" style="color: #333333;">d</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample" style="color: #808080;">---&nbsp;display&nbsp;the&nbsp;total&nbsp;value&nbsp;of&nbsp;deviations&nbsp;at&nbsp;the&nbsp;level&nbsp;of&nbsp;weights&nbsp;in&nbsp;the&nbsp;journal</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_Functions">PrintFormat</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #008080;">&quot;Delta&nbsp;at&nbsp;weights&nbsp;gradient&nbsp;between&nbsp;methods&nbsp;%.5e&quot;</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">dd</span><span class="f_CodeExample">&nbsp;/&nbsp;</span><span class="f_CodeExample" style="color: #333333;">delta</span><span class="f_CodeExample">);</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After completing all the iterations, we clear the memory by deleting the used objects and exit the program.</span></p>
<div style="text-align: justify; text-indent: 0; padding: 0 0 0 0; margin: 7px 17px 6px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;clear&nbsp;the&nbsp;memory&nbsp;before&nbsp;exiting&nbsp;the&nbsp;script</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">init_pattern</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">etalon_result</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">initial_weights</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">target</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The results of my testing are shown in the screenshot below. Based on the testing results, I obtained a deviation in the 11th to 12th decimal place. For comparison, deviations in the 89th decimal places are considered acceptable in different sources. And it's not worth noting that when using OpenCL, the deviation turned out to be an order of magnitude smaller. This is not an advantage of using technology, but rather the influence of a random factor. At each run, a random matrix of weights and initial data was re-generated. As a result, the comparison was carried out on different parts of the neural network function with different curvature. </span></p>
<div class="p_Text" style="text-align: center;"><div style="margin:0 auto 0 auto;width:554px"><img class="help" id="test_gradient" alt="Results of comparing analytical and empirical error gradients" title="Results of comparing analytical and empirical error gradients" width="554" height="161" style="width:554px;height:161px;border:none" src="test_gradient.png"/><p style="text-align:center"><span class="f_ImageCaption">Results of comparing analytical and empirical error gradients</span></p></div></div>
<p class="p_Text"><span class="f_Text">In general, we can say that the testing confirmed the correctness of our implementation of the error backpropagation algorithm both by means of MQL5 and using the OpenCL multi-threaded computing technology. Our next step is to assemble a more complex perceptron, and we will try to train it on a training set.</span></p>

</div>

</body>
</html>
