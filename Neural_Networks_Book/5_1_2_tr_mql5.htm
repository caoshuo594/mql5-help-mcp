<!DOCTYPE html>
<html>
  <head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
  <title>5.1.2 Building Self-Attention with MQL5 tools</title>
  <meta name="keywords" content="" />
  <link type="text/css" href="default.css" rel="stylesheet" />

   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>


</head>

<body style="background-color:#FFFFFF; font-family:'Trebuchet MS',Tahoma,Arial,Helvetica,sans-serif; margin:0px;">



<table width="100%" height="49"  border="0" cellpadding="0" cellspacing="0" style="margin-top:0px; background-color:#1660af;">
  <tr>
    <td></td>
    <td valign="middle">
      <table style="margin-top:4px; margin-bottom:5px;" width="100%"  border="0" cellspacing="0" cellpadding="5">
        <tr valign="middle">
          <td class="nav">
<a class="h_m" href="index.htm">          Neural Networks for Algorithmic Trading with MQL5 </a> / <a class="h_m" href="5_transformer.htm"> 5. Attention mechanisms </a> / <a class="h_m" href="5_1_self-attention.htm"> 5.1 Self-Attention </a>/ 5.1.2 Building Self-Attention with MQL5 tools
          </td>
          <td width="70" align="right">
          <a href="5_1_1_tr_descrption.htm"><img style="vertical-align:middle;" src="previous.png" alt="?????" width="27" height="27" border=0></a>&nbsp;
          <a href="5_1_2_1_tr_feedforward.htm"><img style="vertical-align:middle;" src="next.png" alt="??????" width="27" height="27" border="0"></a>
          </td>
        </tr>
      </table>
    </td>
    <td width="5"></td>
  </tr>
</table>



<div id="help">
<p class="p_H3"><span class="f_H3">5.1.2 Building Self-Attention with MQL5 tools</span></p>
<p class="p_Text"><span class="f_Text">The presented </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> architecture may seem rather difficult to understand and to implement after the first acquaintance. Let's not be pessimistic. We will try to break down the whole algorithm into small components. Then, with the implementation of each individual block, we will assemble the overall picture, and it will no longer be so complex to understand. At the same time, you will be amazed at how we manage the work and build a functional mechanism for our library.</span></p>
<p class="p_Text"><span class="f_Text">Now let's get to work. To implement our </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> layer, let's create a new </span><span class="f_Text" style="font-style: italic;">CNeuronAttention</span><span class="f_Text"> class. As always, we will inherit from our base class of the neural layer, </span><span class="f_Text" style="font-style: italic;">CNeuronBase</span><span class="f_Text">.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CMyOpenCL</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">opencl</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CalcHiddenGradient</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CalcDeltaWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">UpdateWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">batch_size</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">learningRate</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Definition">VECTOR</span><span class="f_CodeExample">&nbsp;&amp;</span><span class="f_CodeExample" style="color: #333333;">Beta</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">VECTOR</span><span class="f_CodeExample">&nbsp;&amp;</span><span class="f_CodeExample" style="color: #333333;">Lambda</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---&nbsp;methods&nbsp;of&nbsp;working&nbsp;with&nbsp;files</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Save</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">file_handle</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Load</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">file_handle</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---object&nbsp;identification&nbsp;method</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Type</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;{&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">(</span><span class="f_Definition">defNeuronAttention</span><span class="f_CodeExample">);&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Let's consider the first action of the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> algorithm which is the computation of the </span><span class="f_Text" style="font-style: italic;">Query</span><span class="f_Text">, </span><span class="f_Text" style="font-style: italic;">Key</span><span class="f_Text">, and </span><span class="f_Text" style="font-style: italic;">Value</span><span class="f_Text"> vectors. At the input, we get a tensor of raw data containing features for each bar of the analyzed sequence. Sequentially, we take the features of one candlestick and, by multiplying them with a weight matrix, obtain a vector. Then we take the features of the second candlestick and multiply them by the same weight matrix so we get the second vector similar to the first one. Does this look similar to the convolution layer created earlier? Here, the length of the result vector is equal to the number of filters used in the convolution layer. Hence, to organize the above process, we declare three nested convolutional layers </span><span class="f_Text" style="font-style: italic;">CNeuronConv.</span><span class="f_Text"> We use the appropriate layer names to make the code easier to read.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">protected</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cQuerys</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cKeys</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cValues</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">According to this algorithm, in the next step, we determine the </span><span class="f_Text" style="font-style: italic;">Score</span><span class="f_Text"> matrix by multiplying the </span><span class="f_Text" style="font-style: italic;">Query </span><span class="f_Text">and </span><span class="f_Text" style="font-style: italic;">Key</span><span class="f_Text"> matrices. To write the matrix data, we will create a data buffer as an object of the </span><span class="f_Text" style="font-style: italic;">CBufferType</span><span class="f_Text"> class.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">protected</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After determining the </span><span class="f_Text" style="font-style: italic;">Score</span><span class="f_Text"> dependency coefficient matrix, we will need to find the weighted values. To do this, we multiply the </span><span class="f_Text" style="font-style: italic;">Values</span><span class="f_Text"> vectors by the corresponding values of the </span><span class="f_Text" style="font-style: italic;">Score</span><span class="f_Text"> matrix. After additional processing, we obtain a tensor equal to the size of the initial data. We will talk about the reasons for the same size during the implementation process. Right now, let's just note for ourselves the need for a data warehouse. To collect data in the storage, we will need to set up a new process, so we require an object with easy access for writing data. In the future, we plan to pass data as input to the internal neural layer. So, the neural layer template of the raw data will be the most suitable for us. We use a basic neural layer with zero input window as the input data layer.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">protected</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cAttentionOut</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Here, it's important to note the difference between the output of the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> algorithm and the output of the entire </span><span class="f_Text" style="font-style: italic;">CNeuronAttention</span><span class="f_Text"> class. The first one is obtained after execution of the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> algorithm by adjusting the values of </span><span class="f_Text" style="font-style: italic;">Value</span><span class="f_Text"> vectors. We save it to the instance of the object of the basic neural layer </span><span class="f_Text" style="font-style: italic;">m_cAttentionOut</span><span class="f_Text">. The second one is obtained after processing in the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block. This one is saved to the result buffer of our class.</span></p>
<p class="p_Text"><span class="f_Text">So, next, we need to organize the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block. We will create it from two consecutive convolution layers. It may seem unusual to use a convolutional layer when the solution architecture is described as having fully connected layers. The situation here is similar to the first point of the algorithm when we determined the value of </span><span class="f_Text" style="font-style: italic;">Query</span><span class="f_Text">, </span><span class="f_Text" style="font-style: italic;">Key</span><span class="f_Text">, and </span><span class="f_Text" style="font-style: italic;">Value</span><span class="f_Text"> vectors. Looking at the block within the context of one element of the sequence, we can see two fully connected neural layers. However, when considering the entire time series, it becomes evident that the same weight matrix is applied sequentially to each element of the sequence. Furthermore, as the input data progresses sequentially, the results are laid out in the same order. Doesn't this resemble the operation of a convolutional layer? We just need to take the convolution layer and set the width of the source data window equal to the vector size of one sequence element. The step of the initial data window is set equal to the window width, and the number of filters used is determined by the size of the fully connected layer for one element of the sequence.</span></p>
<p class="p_Text"><span class="f_Text">Thus, we add two convolution layers to organize the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">protected</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;.....</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">We identified the objects we need to organize the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> mechanism in our class. To complete the picture, let's add a few more variables:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">m_iWindow</span><span class="f_li"> – width of the initial data window (size of one sequence element vector)</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">m_iUnits</span><span class="f_li"> – the number of units in the sequence</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">m_iKeysSize</span><span class="f_li"> – width of the result vector size for </span><span class="f_li" style="font-style: italic;">Query</span><span class="f_li"> and </span><span class="f_li" style="font-style: italic;">Key</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">m_dStd – </span><span class="f_li">during normalization of the layer, we will divide the value by the standard deviation and will save the result to determine the derivative</span></li>
</ul>
<p class="p_Text"><span class="f_Text">Taking into account the standard set of functions for overriding, the class structure will have the following form.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">class</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #0000ff;">protected</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cQuerys</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cKeys</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cValues</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScoreGrad</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScoreTemp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cAttentionOut</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronConv</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iWindow</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iUnits</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iKeysSize</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CBufferType</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cStd</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">public</span><span class="f_CodeExample">:</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CMyOpenCL</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">opencl</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">FeedForward</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CalcHiddenGradient</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CalcDeltaWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">prevLayer</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">UpdateWeights</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">batch_size</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">learningRate</span><span class="f_CodeExample">,</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_Definition">VECTOR</span><span class="f_CodeExample">&nbsp;&amp;</span><span class="f_CodeExample" style="color: #333333;">Beta</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">VECTOR</span><span class="f_CodeExample">&nbsp;&amp;</span><span class="f_CodeExample" style="color: #333333;">Lambda</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---&nbsp;methods&nbsp;for&nbsp;operations&nbsp;with&nbsp;files</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Save</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">file_handle</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Load</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">file_handle</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #808080;">//---&nbsp;object&nbsp;identification&nbsp;method</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">virtual</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">int</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Type</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">)&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">override</span><span class="f_CodeExample">&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;{&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">(</span><span class="f_Definition">defNeuronAttention</span><span class="f_CodeExample">);&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;};</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">In the class constructor, we only set the initial values of the variables.</span></p>
<p class="p_Text"><span class="f_Text">Please note that in this class, we are using static objects rather than pointers to objects as we did previously. The lifetime of static objects, like variables, is equal to the lifetime of the object containing them. By using such objects, we avoid the need to create object instances during class initialization and to clean up memory when the class operation is completed. Also, we don't need to check the validity of the object pointer every time. This saves some time in performing each method. However, in this case, we cannot replace objects by copying only the object's pointer, which this property is actively used in our activation class and in recurrent networks (using the same object pointers when analyzing the entire depth of the history).</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">::</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">)&nbsp;:&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iWindow</span><span class="f_CodeExample">(</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iUnits</span><span class="f_CodeExample">(</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0</span><span class="f_CodeExample">),</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iKeysSize</span><span class="f_CodeExample">(</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cStd</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferInit</span><span class="f_CodeExample">(</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">2</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Since we use static objects, we leave the class destructor empty.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">::~</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">void</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">&nbsp;</span></p>
<p class="p_H3"><span class="f_H3">Method of class initialization</span></p>
<p class="p_Text"><span class="f_Text">After creating the class constructor and destructor, we move on to overriding the main methods of the class. First, we will override the class initialization method </span><span class="f_Text" style="font-style: italic;">CNeuronAttention::Init</span><span class="f_Text">. The main task of this method is to prepare the class to perform its functionality with user-defined parameters. Like similar methods in other previously discussed classes, the method receives an instance of the </span><span class="f_Text" style="font-style: italic;">CLayerDescription</span><span class="f_Text"> object as a parameter, in which the parameters of the initialized neural layer are specified. Therefore, in order to eliminate possible errors in future work, we organize the block of initial data verification. In this method, we will check for the presence of the minimum required parameters in the received data.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">::</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #0000ff;">const</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample" style="color: #808080;">//---&nbsp;check&nbsp;the&nbsp;initial&nbsp;data</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">&nbsp;||&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;!=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">Type</span><span class="f_CodeExample">()&nbsp;||&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;&lt;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">0</span><span class="f_CodeExample">&nbsp;||</span>
<br><span class="f_CodeExample" style="color: #333333;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">&nbsp;&lt;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">0</span><span class="f_CodeExample">&nbsp;||&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;&lt;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">0</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After that, we will save the main parameters into specially prepared variables. Note the correlation between the parameters of the neural layer description class and their functional purpose:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li" style="font-style: italic;">CLayerDescription.window</span><span class="f_li"> – the size of the source data window, a vector of source data of one element of the sequence (in our case description of one bar)</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">CLayerDescription.count</span><span class="f_li"> – the number of elements in the sequence (the number of analyzed bars)</span></li>
<li class="p_li"><span class="f_li" style="font-style: italic;">CLayerDescription.window_out</span><span class="f_li"> – size of the result vector for </span><span class="f_li" style="font-style: italic;">Query</span><span class="f_li"> and </span><span class="f_li" style="font-style: italic;">Key</span></li>
</ul>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iWindow</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iUnits</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iKeysSize</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">As before, we start initializing the object by calling a similar initialization method of the parent class. But there's a nuance here. We cannot simply transfer the resulting description of the neural layer. We will create a new instance of the neural layer description object and </span><span class="f_Text" style="font-style: italic;">CLayerDescription</span><span class="f_Text"> and enter the corrected data into it.</span></p>
<p class="p_Text"><span class="f_Text">In the </span><span class="f_Text" style="font-style: italic;">count</span><span class="f_Text"> field, we specify the total number at the output of the layer, which is obtained by multiplying the </span><span class="f_Text" style="font-style: italic;">count</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">window</span><span class="f_Text"> fields of this object.</span></p>
<p class="p_Text"><span class="f_Text">Note that to obtain the total number of elements in the output of the neural layer, we multiply the number of elements in the sequence (number of bars analyzed) by the size of the source window (elements describing 1 bar), not the size of the results window. The reason is that we will use the results window size only for </span><span class="f_Text" style="font-style: italic;">Query</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">Key</span><span class="f_Text"> tensors. The size of the result vector for the </span><span class="f_Text" style="font-style: italic;">Value</span><span class="f_Text"> tensors and the second layer of the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block will be equal to the size of the initial data window. This is done to align the dimensionality of the initial data and the results. The algorithm involves adding the tensors of the original data to the results of the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> block and then adding the tensors of the results of the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> blocks, as well. Thus, as a result of tensor addition, the sequence at the output of our neural layer cannot be shorter than the initial data. And it doesn't make any sense to increase it. Therefore, we align the dimensions of the vectors.</span></p>
<p class="p_Text"><span class="f_Text">In addition to changing the number of elements, we will also change the size of the output window, setting it to one. The size of the initial data window will be equal to zero. After that, we will call the parent class initialization method.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;calling&nbsp;the&nbsp;parent&nbsp;class&nbsp;initialization&nbsp;method</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">new</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CLayerDescription</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;*&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">optimization</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">optimization</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type&nbsp;</span><span class="f_CodeExample">=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">::</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Such a parameter substitution will allow the running of the parent class initialization method in the neural layer mode of the source data. At the same time, no additional buffers will be created for the weight matrix, as well as the corresponding optimization method buffers. As with the LSTM block, this neural layer will not have a separate weight matrix. All weight factors will be stored in the inner neural layers.</span></p>
<p class="p_Text"><span class="f_Text">We specify a similar architecture for the inner data collection layer of the </span><span class="f_Text" style="font-style: italic;">AttentionOut</span><span class="f_Text"> attention block. We will simply change the type of neural layer and explicitly disable the activation function.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;AttentionOut</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">defNeuronBase</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">=</span><span class="f_Definition">AF_NONE</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cAttentionOut</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Next, to initialize our internal neural layers, we need to create a description for them. We fill the previously created instance of the </span><span class="f_Text" style="font-style: italic;">CLayerDescription</span><span class="f_Text"> class with the necessary data. </span><span class="f_li">Almost all of our internal neural layers are convolutional, so in the </span><span class="f_li" style="font-style: italic;">type</span><span class="f_li"> parameter, we will specify </span><span class="f_li" style="font-style: italic;">defNeuronConv</span><span class="f_li">. </span><span class="f_Text">The rest of the parameters are transferred without changes from the obtained external description.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;create&nbsp;a&nbsp;description&nbsp;for&nbsp;the&nbsp;internal&nbsp;neural&nbsp;layers</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">type</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_Definition">defNeuronConv</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iKeysSize</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">step</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Next, we proceed to initialize the internal neural layers. We first initialize the convolution layer to define </span><span class="f_Text" style="font-style: italic;">Query</span><span class="f_Text"> vectors using a pre-built description. Don't forget to check the results of the operations.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;Querys</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cQuerys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)&nbsp;||&nbsp;!</span><span class="f_CodeExample" style="color: #333333;">m_cQuerys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetTransposedOutput</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Note that we use the new </span><span class="f_Text" style="font-style: italic;">CNeuronConv::SetTransposedOutput</span><span class="f_Text"> method after initializing the convolutional neural layer. The reasons for its appearance and its functionality will be discussed a bit later.</span></p>
<p class="p_Text"><span class="f_Text">We initialize the </span><span class="f_Text" style="font-style: italic;">Keys</span><span class="f_Text"> layer using a similar algorithm.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initializing&nbsp;Keys</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cKeys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)&nbsp;||&nbsp;!</span><span class="f_CodeExample" style="color: #333333;">m_cKeys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetTransposedOutput</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Next, initialize the </span><span class="f_Text" style="font-style: italic;">Values</span><span class="f_Text"> layer. We use the above algorithm with a small addition. As mentioned earlier, when initializing this object, the result window is set equal to the input data window. Therefore, we make changes to the neural layer description object and call the initialization method. Let's check the result of the operations.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;Values</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_iWindow</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cValues</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)&nbsp;||&nbsp;!</span><span class="f_CodeExample" style="color: #333333;">m_cValues</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetTransposedOutput</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Next, we initialize the </span><span class="f_Text" style="font-style: italic;">Scores</span><span class="f_Text"> coefficient matrix. According to the </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> mechanism algorithm, this is a square matrix with a side length equal to the number of elements in the sequence. For us, it is the number of bars analyzed.</span></p>
<p class="p_Text"><span class="f_Text">In the discussion of this algorithm, it's important to understand the difference between the </span><span class="f_Text" style="font-style: italic;">number of elements in the sequence</span><span class="f_Text"> and the total </span><span class="f_Text" style="font-style: italic;">number of elements at the output of the neural layer</span><span class="f_Text">. If you translate this to analyzing a candlestick chart of a change in a stock instrument, then:</span></p>
<ul style="list-style-type:disc">
<li class="p_li"><span class="f_li">The number of elements in a sequence is the number of bars to be analyzed.</span></li>
<li class="p_li"><span class="f_li">The length of a vector of one sequence element (input / output window) is the number of elements describing 1 bar.</span></li>
<li class="p_li"><span class="f_li">The total number of elements at the input/output of the neural layer is the product of the first two quantities.</span></li>
</ul>
<p class="p_Text"><span class="f_Text">Let's return to the initialization of the coefficient matrix buffer. For it, we have declared a data buffer. We will initialize it with zero values by setting the buffer size as a square matrix.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;Scores</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferInit</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">,&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">count</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The </span><span class="f_Text" style="font-style: italic;">Self-Attention</span><span class="f_Text"> algorithm is followed by the base neural layer object for recording attention results, which we have already initialized above.</span></p>
<p class="p_Text"><span class="f_Text">All we have to do is initialize the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block. As mentioned, it will consist of two convolutional neural layers. According to the architecture proposed by the authors, in the first neural layer, the tensor of results is four times larger than the input data. In addition, the authors used the </span><span class="f_Text" style="font-style: italic;">ReLU</span><span class="f_Text"> activation function in the first neuron layer. We'll replace it with </span><span class="f_Text" style="font-style: italic;">Swish</span><span class="f_Text">. We will make the specified changes to the description of the neural layer and proceed with its initialization.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;FF1</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;*=&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">4</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">AF_SWISH</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">[</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">1</span><span class="f_CodeExample">]&nbsp;=&nbsp;</span><span class="f_Normal" style="font-family: Arial,Helvetica,sans-serif; color: #000000; background-color: transparent;">0</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cFF1</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)&nbsp;||&nbsp;!</span><span class="f_CodeExample" style="color: #333333;">m_cFF1</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetTransposedOutput</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">To initialize the second neural layer in the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block, we need to increase the size of the input data window and its stride. The size of the results window should be resized to match the size of the attention block results tensor. It will also correspond to the tensor size of the previous layer.</span></p>
<p class="p_Text"><span class="f_Text">For the second neural layer in the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text">, we will use the activation function specified by the user during the initialization of our class.</span></p>
<p class="p_Text"><span class="f_Text">After making the necessary changes to the description object of the neural layer, we will use the algorithm discussed earlier to initialize the last internal neural layer.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;initialize&nbsp;FF2</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window_out</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">step</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">step</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">window</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">desc</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">activation_params</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(!</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Init</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">)&nbsp;||&nbsp;!</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetTransposedOutput</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">))</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">false</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">temp</span><span class="f_CodeExample">;</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">After initializing all internal neural layers, we delete the temporary neural layer description object. We don't need it anymore.</span></p>
<p class="p_Text"><span class="f_Text">Now let's use a little trick. According to the algorithm, we obtain the result of the second neural layer operation in the result buffer of the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block's second layer. To transfer the data to the subsequent neural layer, we need to transfer the data to the result buffer of our class. We will need additional time and resources at each iteration for the data copy operation. To avoid this, we can substitute pointers to objects. Remember that we discussed objects and pointers to them?</span></p>
<p class="p_Text"><span class="f_Text">Initially, we delete the result buffer object of our class to avoid leaving unaccounted objects in memory. Then, in the variable used to store the pointer to the buffer object, we assign the pointer to a similar buffer in the second neural layer of the </span><span class="f_Text" style="font-style: italic;">Feed Forward</span><span class="f_Text"> block. The same operation is performed for the gradient buffer.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;to&nbsp;avoid&nbsp;copying&nbsp;the&nbsp;buffers&nbsp;we&nbsp;swap&nbsp;them</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOutputs</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cOutputs</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cOutputs</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetOutputs</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cGradients</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">delete</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cGradients</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cGradients</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">GetGradients</span><span class="f_CodeExample">();</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Thanks to this simple trick, we have been able to avoid constant data copying between buffers and reduce the time required to perform operations within the class.</span></p>
<p class="p_Text"><span class="f_Text">In conclusion, at the end of the initialization method, we call the </span><span class="f_Text" style="font-style: italic;">SetOpenCL</span><span class="f_Text"> method to ensure that all our internal objects work in the same context. Now we exit the method with a positive result.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #808080;">//---&nbsp;pass&nbsp;a&nbsp;pointer&nbsp;to&nbsp;the&nbsp;object&nbsp;of&nbsp;work&nbsp;with&nbsp;OpenCL&nbsp;before&nbsp;all&nbsp;internal&nbsp;objects</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #ff0000;">true</span><span class="f_CodeExample">;</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">The </span><span class="f_Text" style="font-style: italic;">SetOpenCL</span><span class="f_Text"> method, called at the end of the initialization method, is designed to distribute the pointer to the </span><span class="f_Text" style="font-style: italic;">OpenCL</span><span class="f_Text"> context work object among all internal objects. This is necessary to ensure that all objects work in the same space. This method was created as virtual in the base class of the neural layer. It is redefined in each new class as needed.</span></p>
<p class="p_Text"><span class="f_Text">The algorithm of the method is quite simple, and we have already discussed it in all the previous classes. In the parameters, the method receives a pointer of the object of work with </span><span class="f_Text" style="font-style: italic;">OpenCL</span><span class="f_Text"> context from an external program. We simply start by calling the method of the parent class and pass it the obtained pointer. The validation of the obtained pointer is already implemented in the parent class's method, so there is no need to repeat it here.</span></p>
<p class="p_Text"><span class="f_Text">Then we pass the pointer to the </span><span class="f_Text" style="font-style: italic;">OpenCL</span><span class="f_Text"> context to all internal objects stored in the variable of our class. The trick is that the method of the parent class checks the obtained pointer and stores the appropriate pointer in the variable. To ensure that all objects work in the same context, we propagate the already processed pointer.</span></p>
<div style="text-align: left; text-indent: 0; line-height: 1.0; page-break-inside: avoid; page-break-after: avoid; border-color: #d8dfea; border-style: solid; border-width: thin; background: #fbf9f5; padding: 0 0 0 0; margin: 2px 17px 2px 17px;"><table cellspacing="0" cellpadding="3" border="0" style="text-align: justify;border:none; border-spacing:0;">
<tr>
<td style="vertical-align:top; padding:3px; border:none"><p class="p_CodeExample" style="page-break-inside: avoid; page-break-after: avoid;"><span class="f_CodeExample" style="color: #0000ff;">bool</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronAttention</span><span class="f_CodeExample">::</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">CMyOpenCL</span><span class="f_CodeExample">&nbsp;*</span><span class="f_CodeExample" style="color: #333333;">opencl</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">CNeuronBase</span><span class="f_CodeExample">::</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">opencl</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cQuerys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cKeys</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cValues</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cAttentionOut</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF1</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cFF2</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">SetOpenCL</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">if</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">)</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferCreate</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">ulong</span><span class="f_CodeExample">&nbsp;</span><span class="f_CodeExample" style="color: #333333;">size</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">sizeof</span><span class="f_CodeExample">(</span><span class="f_Definition">TYPE</span><span class="f_CodeExample">)&nbsp;*&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">Total</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScoreGrad</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">AddBuffer</span><span class="f_CodeExample">((</span><span class="f_CodeExample" style="color: #0000ff;">uint</span><span class="f_CodeExample">)</span><span class="f_CodeExample" style="color: #333333;">size</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">CL_MEM_READ_WRITE</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScoreTemp</span><span class="f_CodeExample">&nbsp;=&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">AddBuffer</span><span class="f_CodeExample">((</span><span class="f_CodeExample" style="color: #0000ff;">uint</span><span class="f_CodeExample">)</span><span class="f_CodeExample" style="color: #333333;">size</span><span class="f_CodeExample">,&nbsp;</span><span class="f_Definition">CL_MEM_READ_WRITE</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cStd</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferCreate</span><span class="f_CodeExample">(</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">else</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cScores</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferFree</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #333333;">m_cStd</span><span class="f_CodeExample">.</span><span class="f_CodeExample" style="color: #333333;">BufferFree</span><span class="f_CodeExample">();</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span>
<br><span class="f_CodeExample" style="color: #808080;">//---</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;&nbsp;</span><span class="f_CodeExample" style="color: #0000ff;">return</span><span class="f_CodeExample">(!!</span><span class="f_CodeExample" style="color: #333333;">m_cOpenCL</span><span class="f_CodeExample">);</span>
<br><span class="f_CodeExample">&nbsp;&nbsp;}</span></p>
</td>
</tr>
</table>
</div>
<p class="p_Text"><span class="f_Text">Going a bit ahead, I want to draw attention to the creation of the </span><span class="f_Text" style="font-style: italic;">m_cScoreGrad</span><span class="f_Text"> and </span><span class="f_Text" style="font-style: italic;">m_cScoreTemp</span><span class="f_Text"> buffers. They are used only in the OpenCL context for temporary data storage, so we did not create mirror objects for them in the main memory. Also, we will not use them to exchange data between the main program and the OpenCL context. In this case, we will create buffers in the OpenCL context, while on the side of the main program, we use only pointers to work with them. When disabling multi-threading technology, we immediately delete the mentioned buffers.</span></p>
<p class="p_Text"><span class="f_Text">After completing the initialization method of the class, we can proceed to override the functional methods of our class.</span></p>

</div>

</body>
</html>
